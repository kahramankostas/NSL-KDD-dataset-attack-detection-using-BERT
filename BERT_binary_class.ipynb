{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25240,
     "status": "ok",
     "timestamp": 1596405246626,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "aV2DOOc59Peg",
    "outputId": "2e803112-2bd6-40ca-bfac-e0d8711bd0d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 26.8MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 20kB 20.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 30kB 15.6MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 40kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 51kB 8.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 61kB 9.3MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 71kB 9.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 81kB 8.9MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 92kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 102kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 112kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 122kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 133kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 143kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 153kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 163kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 174kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 184kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 194kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 204kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 215kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 225kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 235kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 245kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 256kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 266kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 276kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 286kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 296kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 307kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 317kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 327kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 337kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 348kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 358kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 368kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 378kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 389kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 399kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 409kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 419kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 430kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 440kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 450kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 460kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 471kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 481kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 491kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 501kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 512kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 522kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 532kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 542kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 552kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 563kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 573kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 583kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 593kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 604kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 614kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 624kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 634kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 645kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 655kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 665kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 675kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 686kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 696kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 706kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 716kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 727kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 737kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 747kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 757kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 768kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 778kB 9.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 87kB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 41.5MB/s \n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 50.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4ef321c4d462fef5da99ce0e86de76d589c6ba2745c32f19f971a88e95aa1b29\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "!pip install transformers\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1685,
     "status": "ok",
     "timestamp": 1596405248317,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "eJqm3Bcj9uxl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12031,
     "status": "ok",
     "timestamp": 1596405258681,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "9gZ9tVoZ9ay5",
    "outputId": "bce7fdbb-cbcb-48f7-cbe3-9fca67f0a221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == '/device:GPU:0':\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70293,
     "status": "ok",
     "timestamp": 1596405318509,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "tAZF9F7s9jWu",
    "outputId": "6ac32616-049e-4cc6-8637-9bea074e628f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# set environment as googledrive to folder \"resource\"\n",
    "data_path =  \"/resource/\"\n",
    "\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    data_path = \"/content/drive/My Drive/resource/\"\n",
    "\n",
    "except:\n",
    "    print(\"You are not working in Colab at the moment :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4948,
     "status": "ok",
     "timestamp": 1596405323488,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "_qSyeNZk9jaR",
    "outputId": "261c8b55-68e6-4621-aec1-0ae21cd011ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_categories\n",
      "0    58630\n",
      "1    67343\n",
      "dtype: int64\n",
      "encoded_categories\n",
      "0    12833\n",
      "1     9710\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(data_path + 'new_train.csv',sep=\"\\t\")\n",
    "df['encoded_categories'] = df['category']==\"normal\"\n",
    "df['encoded_categories']=df['encoded_categories'].astype('int')\n",
    "df1 = pd.read_csv(data_path + 'new_test.csv',sep=\"\\t\")\n",
    "df1['encoded_categories'] = df1['category']==\"normal\"\n",
    "df1['encoded_categories']=df1['encoded_categories'].astype('int')\n",
    "print(df.groupby(\"encoded_categories\").size())\n",
    "print(df1.groupby(\"encoded_categories\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "44651e87ca8b4ab4a1880859ec7cea7b",
      "21a9dd1473424c2ca62e53980ee10439",
      "1bb55a0c4c4a4448a39bb66fb0e43851",
      "ea93e197c46c4ed8981fea8d9e19c519",
      "08ac5211d1d1457d887c05637b765cba",
      "035fba578fa64556af099baea4e26b89",
      "8a4909a5b6e84526af54a013a2ce0d0d",
      "f351d360263a4bb3bd2e47db1a549338"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7429,
     "status": "ok",
     "timestamp": 1596405337348,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "uR8vqJIs9jdm",
    "outputId": "cf86678a-248e-4b56-9d4a-702fc7be639b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44651e87ca8b4ab4a1880859ec7cea7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "sentences = df.text.values\n",
    "max_len = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3598,
     "status": "ok",
     "timestamp": 1596405337350,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "P-JzAFrn9lMb",
    "outputId": "17833f7c-35d4-4da2-bf23-ebae65435ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tcp ftp_data SF 491 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 1 0 0 150 25 0.17 0.03 0.17 0 0 0 0.05 0\n",
      "['0', 'tc', '##p', 'ft', '##p', '_', 'data', 'sf', '49', '##1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2', '2', '0', '0', '0', '0', '1', '0', '0', '150', '25', '0', '.', '17', '0', '.', '03', '0', '.', '17', '0', '0', '0', '0', '.', '05', '0']\n",
      "[1014, 22975, 2361, 3027, 2361, 1035, 2951, 16420, 4749, 2487, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1016, 1016, 1014, 1014, 1014, 1014, 1015, 1014, 1014, 5018, 2423, 1014, 1012, 2459, 1014, 1012, 6021, 1014, 1012, 2459, 1014, 1014, 1014, 1014, 1012, 5709, 1014]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(tokenizer.tokenize(sentences[0]))\n",
    "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n",
    "#print(max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56791,
     "status": "ok",
     "timestamp": 1596380648253,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "ExxXme17sevI",
    "outputId": "b68efaf3-a660-41bb-895b-f7495879ec57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  0 tcp ftp_data SF 491 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 1 0 0 150 25 0.17 0.03 0.17 0 0 0 0.05 0\n",
      "Token IDs: [101, 1014, 22975, 2361, 3027, 2361, 1035, 2951, 16420, 4749, 2487, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1014, 1016, 1016, 1014, 1014, 1014, 1014, 1015, 1014, 1014, 5018, 2423, 1014, 1012, 2459, 1014, 1012, 6021, 1014, 1012, 2459, 1014, 1014, 1014, 1014, 1012, 5709, 1014, 102]\n"
     ]
    }
   ],
   "source": [
    "#EKKKKKKKKKKKKKKKKKK\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "                        # This function also supports truncation and conversion\n",
    "                        # to pytorch tensors, but we need to do padding, so we\n",
    "                        # can't use these features :( .\n",
    "                        #max_length = 128,          # Truncate all sentences.\n",
    "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1596380649162,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "EX0sHKn3ssIW",
    "outputId": "04f2d924-018c-4bf3-c28e-837d6aa71221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  75\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2214,
     "status": "ok",
     "timestamp": 1596405344036,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "ioBjtxOx9jgu",
    "outputId": "df022ab0-403b-4d3e-d28d-310a8e763bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  125973\n",
      "Test:  22543\n"
     ]
    }
   ],
   "source": [
    "training = df\n",
    "test = df1\n",
    "\n",
    "print(\"Training: \", len(training))\n",
    "print(\"Test: \", len(test))\n",
    "\n",
    "training_texts = training.text.values\n",
    "training_labels = training.encoded_categories.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQ2Kb5B29a4A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1600,
     "status": "ok",
     "timestamp": 1596405347415,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "8a3k6QiaaUf1",
    "outputId": "c7cf4b0a-6154-4f0f-f66a-19ffc59c1adb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "DoS       7458\n",
      "Probe     2421\n",
      "R2L       2754\n",
      "U2R        200\n",
      "normal    9710\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#training_labels = training.encoded_categories.values\n",
    "print(test.groupby(\"category\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 68787,
     "status": "ok",
     "timestamp": 1596405419617,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "RipYsk5B9jkJ",
    "outputId": "13779534-275a-4323-f5e5-36268afeabdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  0 tcp ftp_data SF 491 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 1 0 0 150 25 0.17 0.03 0.17 0 0 0 0.05 0\n",
      "Token IDs: tensor([  101,  1014, 22975,  2361,  3027,  2361,  1035,  2951, 16420,  4749,\n",
      "         2487,  1014,  1014,  1014,  1014,  1014,  1014,  1014,  1014,  1014,\n",
      "         1014,  1014,  1014,  1014,  1014,  1014,  1014,  1014,  1016,  1016,\n",
      "         1014,  1014,  1014,  1014,  1015,  1014,  1014,  5018,  2423,  1014,\n",
      "         1012,  2459,  1014,  1012,  6021,  1014,  1012,  2459,  1014,  1014,\n",
      "         1014,  1014,  1012,  5709,  1014,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in training_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = max_len,      \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True, \n",
    "                        return_tensors = 'pt',\n",
    "                        truncation=True,\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(training_labels)\n",
    "\n",
    "print('Original: ', training_texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1e733c554f4c4ca490794fb866672710",
      "5411e6b4691c43a396a4e9a88e54e114",
      "17f3da9b03854f55a8505d1a997c6c18",
      "22763bcb42b64b9d9f6988e145370ff4",
      "385fcdef15b544209f67c26ec3d8370c",
      "1fb81158de864bf6824f480a5b4a9d88",
      "0318e852cb824e878ae18e804de01dea",
      "15b7f2dc8b2d4672872fabc4ca1fd406",
      "b80020ed3de9443ebef2a6dcbc7927d8",
      "7ad074cbcbff4e038804091fb1fd6eaa",
      "45c40ff09909429a9ebfacb711811549",
      "2e50e4763fee4f0a8a961179312985b9",
      "e0e1e026305a4dc5aed6f1640957d7ac",
      "8272b67f36384027804f020609eba4dd",
      "d06ec224e4844886948b90d154185ddb",
      "ff8fdb69821c4780ac10d26965e350fe"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24099,
     "status": "ok",
     "timestamp": 1596405443754,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "eOU8SCeu-ZTH",
    "outputId": "dd836923-0e85-4898-b7ba-87dd80348231"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e733c554f4c4ca490794fb866672710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80020ed3de9443ebef2a6dcbc7927d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "model=\"\"\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = batch_size \n",
    "        )\n",
    "\n",
    "number_of_categories = len(df['encoded_categories'].unique())\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = number_of_categories, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XelXWmuvY3Ct"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24092,
     "status": "ok",
     "timestamp": 1596405443756,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "TgYF0qYe-ZWW"
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5,\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7241303,
     "status": "ok",
     "timestamp": 1596412660982,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "okCbfLuH-ZZw",
    "outputId": "e41de50e-97fd-435f-eaf7-1b846d489140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Batch    10  of  3,937.    Elapsed: 0:00:05.\n",
      "Batch    20  of  3,937.    Elapsed: 0:00:09.\n",
      "Batch    30  of  3,937.    Elapsed: 0:00:14.\n",
      "Batch    40  of  3,937.    Elapsed: 0:00:19.\n",
      "Batch    50  of  3,937.    Elapsed: 0:00:23.\n",
      "Batch    60  of  3,937.    Elapsed: 0:00:28.\n",
      "Batch    70  of  3,937.    Elapsed: 0:00:33.\n",
      "Batch    80  of  3,937.    Elapsed: 0:00:38.\n",
      "Batch    90  of  3,937.    Elapsed: 0:00:43.\n",
      "Batch   100  of  3,937.    Elapsed: 0:00:48.\n",
      "Batch   110  of  3,937.    Elapsed: 0:00:52.\n",
      "Batch   120  of  3,937.    Elapsed: 0:00:57.\n",
      "Batch   130  of  3,937.    Elapsed: 0:01:02.\n",
      "Batch   140  of  3,937.    Elapsed: 0:01:06.\n",
      "Batch   150  of  3,937.    Elapsed: 0:01:11.\n",
      "Batch   160  of  3,937.    Elapsed: 0:01:15.\n",
      "Batch   170  of  3,937.    Elapsed: 0:01:20.\n",
      "Batch   180  of  3,937.    Elapsed: 0:01:24.\n",
      "Batch   190  of  3,937.    Elapsed: 0:01:29.\n",
      "Batch   200  of  3,937.    Elapsed: 0:01:33.\n",
      "Batch   210  of  3,937.    Elapsed: 0:01:38.\n",
      "Batch   220  of  3,937.    Elapsed: 0:01:42.\n",
      "Batch   230  of  3,937.    Elapsed: 0:01:47.\n",
      "Batch   240  of  3,937.    Elapsed: 0:01:52.\n",
      "Batch   250  of  3,937.    Elapsed: 0:01:56.\n",
      "Batch   260  of  3,937.    Elapsed: 0:02:01.\n",
      "Batch   270  of  3,937.    Elapsed: 0:02:05.\n",
      "Batch   280  of  3,937.    Elapsed: 0:02:10.\n",
      "Batch   290  of  3,937.    Elapsed: 0:02:15.\n",
      "Batch   300  of  3,937.    Elapsed: 0:02:19.\n",
      "Batch   310  of  3,937.    Elapsed: 0:02:24.\n",
      "Batch   320  of  3,937.    Elapsed: 0:02:29.\n",
      "Batch   330  of  3,937.    Elapsed: 0:02:33.\n",
      "Batch   340  of  3,937.    Elapsed: 0:02:38.\n",
      "Batch   350  of  3,937.    Elapsed: 0:02:43.\n",
      "Batch   360  of  3,937.    Elapsed: 0:02:47.\n",
      "Batch   370  of  3,937.    Elapsed: 0:02:52.\n",
      "Batch   380  of  3,937.    Elapsed: 0:02:56.\n",
      "Batch   390  of  3,937.    Elapsed: 0:03:01.\n",
      "Batch   400  of  3,937.    Elapsed: 0:03:05.\n",
      "Batch   410  of  3,937.    Elapsed: 0:03:10.\n",
      "Batch   420  of  3,937.    Elapsed: 0:03:15.\n",
      "Batch   430  of  3,937.    Elapsed: 0:03:19.\n",
      "Batch   440  of  3,937.    Elapsed: 0:03:24.\n",
      "Batch   450  of  3,937.    Elapsed: 0:03:28.\n",
      "Batch   460  of  3,937.    Elapsed: 0:03:33.\n",
      "Batch   470  of  3,937.    Elapsed: 0:03:38.\n",
      "Batch   480  of  3,937.    Elapsed: 0:03:42.\n",
      "Batch   490  of  3,937.    Elapsed: 0:03:47.\n",
      "Batch   500  of  3,937.    Elapsed: 0:03:51.\n",
      "Batch   510  of  3,937.    Elapsed: 0:03:56.\n",
      "Batch   520  of  3,937.    Elapsed: 0:04:01.\n",
      "Batch   530  of  3,937.    Elapsed: 0:04:05.\n",
      "Batch   540  of  3,937.    Elapsed: 0:04:10.\n",
      "Batch   550  of  3,937.    Elapsed: 0:04:15.\n",
      "Batch   560  of  3,937.    Elapsed: 0:04:19.\n",
      "Batch   570  of  3,937.    Elapsed: 0:04:24.\n",
      "Batch   580  of  3,937.    Elapsed: 0:04:28.\n",
      "Batch   590  of  3,937.    Elapsed: 0:04:33.\n",
      "Batch   600  of  3,937.    Elapsed: 0:04:38.\n",
      "Batch   610  of  3,937.    Elapsed: 0:04:42.\n",
      "Batch   620  of  3,937.    Elapsed: 0:04:47.\n",
      "Batch   630  of  3,937.    Elapsed: 0:04:51.\n",
      "Batch   640  of  3,937.    Elapsed: 0:04:56.\n",
      "Batch   650  of  3,937.    Elapsed: 0:05:01.\n",
      "Batch   660  of  3,937.    Elapsed: 0:05:05.\n",
      "Batch   670  of  3,937.    Elapsed: 0:05:10.\n",
      "Batch   680  of  3,937.    Elapsed: 0:05:14.\n",
      "Batch   690  of  3,937.    Elapsed: 0:05:19.\n",
      "Batch   700  of  3,937.    Elapsed: 0:05:24.\n",
      "Batch   710  of  3,937.    Elapsed: 0:05:28.\n",
      "Batch   720  of  3,937.    Elapsed: 0:05:33.\n",
      "Batch   730  of  3,937.    Elapsed: 0:05:37.\n",
      "Batch   740  of  3,937.    Elapsed: 0:05:42.\n",
      "Batch   750  of  3,937.    Elapsed: 0:05:46.\n",
      "Batch   760  of  3,937.    Elapsed: 0:05:51.\n",
      "Batch   770  of  3,937.    Elapsed: 0:05:56.\n",
      "Batch   780  of  3,937.    Elapsed: 0:06:00.\n",
      "Batch   790  of  3,937.    Elapsed: 0:06:05.\n",
      "Batch   800  of  3,937.    Elapsed: 0:06:09.\n",
      "Batch   810  of  3,937.    Elapsed: 0:06:14.\n",
      "Batch   820  of  3,937.    Elapsed: 0:06:19.\n",
      "Batch   830  of  3,937.    Elapsed: 0:06:23.\n",
      "Batch   840  of  3,937.    Elapsed: 0:06:28.\n",
      "Batch   850  of  3,937.    Elapsed: 0:06:32.\n",
      "Batch   860  of  3,937.    Elapsed: 0:06:37.\n",
      "Batch   870  of  3,937.    Elapsed: 0:06:42.\n",
      "Batch   880  of  3,937.    Elapsed: 0:06:46.\n",
      "Batch   890  of  3,937.    Elapsed: 0:06:51.\n",
      "Batch   900  of  3,937.    Elapsed: 0:06:55.\n",
      "Batch   910  of  3,937.    Elapsed: 0:07:00.\n",
      "Batch   920  of  3,937.    Elapsed: 0:07:05.\n",
      "Batch   930  of  3,937.    Elapsed: 0:07:09.\n",
      "Batch   940  of  3,937.    Elapsed: 0:07:14.\n",
      "Batch   950  of  3,937.    Elapsed: 0:07:18.\n",
      "Batch   960  of  3,937.    Elapsed: 0:07:23.\n",
      "Batch   970  of  3,937.    Elapsed: 0:07:28.\n",
      "Batch   980  of  3,937.    Elapsed: 0:07:32.\n",
      "Batch   990  of  3,937.    Elapsed: 0:07:37.\n",
      "Batch 1,000  of  3,937.    Elapsed: 0:07:41.\n",
      "Batch 1,010  of  3,937.    Elapsed: 0:07:46.\n",
      "Batch 1,020  of  3,937.    Elapsed: 0:07:51.\n",
      "Batch 1,030  of  3,937.    Elapsed: 0:07:55.\n",
      "Batch 1,040  of  3,937.    Elapsed: 0:08:00.\n",
      "Batch 1,050  of  3,937.    Elapsed: 0:08:05.\n",
      "Batch 1,060  of  3,937.    Elapsed: 0:08:09.\n",
      "Batch 1,070  of  3,937.    Elapsed: 0:08:14.\n",
      "Batch 1,080  of  3,937.    Elapsed: 0:08:18.\n",
      "Batch 1,090  of  3,937.    Elapsed: 0:08:23.\n",
      "Batch 1,100  of  3,937.    Elapsed: 0:08:28.\n",
      "Batch 1,110  of  3,937.    Elapsed: 0:08:32.\n",
      "Batch 1,120  of  3,937.    Elapsed: 0:08:37.\n",
      "Batch 1,130  of  3,937.    Elapsed: 0:08:41.\n",
      "Batch 1,140  of  3,937.    Elapsed: 0:08:46.\n",
      "Batch 1,150  of  3,937.    Elapsed: 0:08:51.\n",
      "Batch 1,160  of  3,937.    Elapsed: 0:08:55.\n",
      "Batch 1,170  of  3,937.    Elapsed: 0:09:00.\n",
      "Batch 1,180  of  3,937.    Elapsed: 0:09:04.\n",
      "Batch 1,190  of  3,937.    Elapsed: 0:09:09.\n",
      "Batch 1,200  of  3,937.    Elapsed: 0:09:14.\n",
      "Batch 1,210  of  3,937.    Elapsed: 0:09:18.\n",
      "Batch 1,220  of  3,937.    Elapsed: 0:09:23.\n",
      "Batch 1,230  of  3,937.    Elapsed: 0:09:27.\n",
      "Batch 1,240  of  3,937.    Elapsed: 0:09:32.\n",
      "Batch 1,250  of  3,937.    Elapsed: 0:09:37.\n",
      "Batch 1,260  of  3,937.    Elapsed: 0:09:41.\n",
      "Batch 1,270  of  3,937.    Elapsed: 0:09:46.\n",
      "Batch 1,280  of  3,937.    Elapsed: 0:09:50.\n",
      "Batch 1,290  of  3,937.    Elapsed: 0:09:55.\n",
      "Batch 1,300  of  3,937.    Elapsed: 0:09:59.\n",
      "Batch 1,310  of  3,937.    Elapsed: 0:10:04.\n",
      "Batch 1,320  of  3,937.    Elapsed: 0:10:09.\n",
      "Batch 1,330  of  3,937.    Elapsed: 0:10:13.\n",
      "Batch 1,340  of  3,937.    Elapsed: 0:10:18.\n",
      "Batch 1,350  of  3,937.    Elapsed: 0:10:22.\n",
      "Batch 1,360  of  3,937.    Elapsed: 0:10:27.\n",
      "Batch 1,370  of  3,937.    Elapsed: 0:10:32.\n",
      "Batch 1,380  of  3,937.    Elapsed: 0:10:36.\n",
      "Batch 1,390  of  3,937.    Elapsed: 0:10:41.\n",
      "Batch 1,400  of  3,937.    Elapsed: 0:10:45.\n",
      "Batch 1,410  of  3,937.    Elapsed: 0:10:50.\n",
      "Batch 1,420  of  3,937.    Elapsed: 0:10:55.\n",
      "Batch 1,430  of  3,937.    Elapsed: 0:10:59.\n",
      "Batch 1,440  of  3,937.    Elapsed: 0:11:04.\n",
      "Batch 1,450  of  3,937.    Elapsed: 0:11:08.\n",
      "Batch 1,460  of  3,937.    Elapsed: 0:11:13.\n",
      "Batch 1,470  of  3,937.    Elapsed: 0:11:18.\n",
      "Batch 1,480  of  3,937.    Elapsed: 0:11:22.\n",
      "Batch 1,490  of  3,937.    Elapsed: 0:11:27.\n",
      "Batch 1,500  of  3,937.    Elapsed: 0:11:31.\n",
      "Batch 1,510  of  3,937.    Elapsed: 0:11:36.\n",
      "Batch 1,520  of  3,937.    Elapsed: 0:11:41.\n",
      "Batch 1,530  of  3,937.    Elapsed: 0:11:45.\n",
      "Batch 1,540  of  3,937.    Elapsed: 0:11:50.\n",
      "Batch 1,550  of  3,937.    Elapsed: 0:11:54.\n",
      "Batch 1,560  of  3,937.    Elapsed: 0:11:59.\n",
      "Batch 1,570  of  3,937.    Elapsed: 0:12:04.\n",
      "Batch 1,580  of  3,937.    Elapsed: 0:12:08.\n",
      "Batch 1,590  of  3,937.    Elapsed: 0:12:13.\n",
      "Batch 1,600  of  3,937.    Elapsed: 0:12:17.\n",
      "Batch 1,610  of  3,937.    Elapsed: 0:12:22.\n",
      "Batch 1,620  of  3,937.    Elapsed: 0:12:27.\n",
      "Batch 1,630  of  3,937.    Elapsed: 0:12:31.\n",
      "Batch 1,640  of  3,937.    Elapsed: 0:12:36.\n",
      "Batch 1,650  of  3,937.    Elapsed: 0:12:40.\n",
      "Batch 1,660  of  3,937.    Elapsed: 0:12:45.\n",
      "Batch 1,670  of  3,937.    Elapsed: 0:12:50.\n",
      "Batch 1,680  of  3,937.    Elapsed: 0:12:54.\n",
      "Batch 1,690  of  3,937.    Elapsed: 0:12:59.\n",
      "Batch 1,700  of  3,937.    Elapsed: 0:13:03.\n",
      "Batch 1,710  of  3,937.    Elapsed: 0:13:08.\n",
      "Batch 1,720  of  3,937.    Elapsed: 0:13:13.\n",
      "Batch 1,730  of  3,937.    Elapsed: 0:13:17.\n",
      "Batch 1,740  of  3,937.    Elapsed: 0:13:22.\n",
      "Batch 1,750  of  3,937.    Elapsed: 0:13:26.\n",
      "Batch 1,760  of  3,937.    Elapsed: 0:13:31.\n",
      "Batch 1,770  of  3,937.    Elapsed: 0:13:35.\n",
      "Batch 1,780  of  3,937.    Elapsed: 0:13:40.\n",
      "Batch 1,790  of  3,937.    Elapsed: 0:13:45.\n",
      "Batch 1,800  of  3,937.    Elapsed: 0:13:49.\n",
      "Batch 1,810  of  3,937.    Elapsed: 0:13:54.\n",
      "Batch 1,820  of  3,937.    Elapsed: 0:13:58.\n",
      "Batch 1,830  of  3,937.    Elapsed: 0:14:03.\n",
      "Batch 1,840  of  3,937.    Elapsed: 0:14:08.\n",
      "Batch 1,850  of  3,937.    Elapsed: 0:14:12.\n",
      "Batch 1,860  of  3,937.    Elapsed: 0:14:17.\n",
      "Batch 1,870  of  3,937.    Elapsed: 0:14:21.\n",
      "Batch 1,880  of  3,937.    Elapsed: 0:14:26.\n",
      "Batch 1,890  of  3,937.    Elapsed: 0:14:30.\n",
      "Batch 1,900  of  3,937.    Elapsed: 0:14:35.\n",
      "Batch 1,910  of  3,937.    Elapsed: 0:14:40.\n",
      "Batch 1,920  of  3,937.    Elapsed: 0:14:44.\n",
      "Batch 1,930  of  3,937.    Elapsed: 0:14:49.\n",
      "Batch 1,940  of  3,937.    Elapsed: 0:14:53.\n",
      "Batch 1,950  of  3,937.    Elapsed: 0:14:58.\n",
      "Batch 1,960  of  3,937.    Elapsed: 0:15:03.\n",
      "Batch 1,970  of  3,937.    Elapsed: 0:15:07.\n",
      "Batch 1,980  of  3,937.    Elapsed: 0:15:12.\n",
      "Batch 1,990  of  3,937.    Elapsed: 0:15:16.\n",
      "Batch 2,000  of  3,937.    Elapsed: 0:15:21.\n",
      "Batch 2,010  of  3,937.    Elapsed: 0:15:25.\n",
      "Batch 2,020  of  3,937.    Elapsed: 0:15:30.\n",
      "Batch 2,030  of  3,937.    Elapsed: 0:15:35.\n",
      "Batch 2,040  of  3,937.    Elapsed: 0:15:39.\n",
      "Batch 2,050  of  3,937.    Elapsed: 0:15:44.\n",
      "Batch 2,060  of  3,937.    Elapsed: 0:15:48.\n",
      "Batch 2,070  of  3,937.    Elapsed: 0:15:53.\n",
      "Batch 2,080  of  3,937.    Elapsed: 0:15:58.\n",
      "Batch 2,090  of  3,937.    Elapsed: 0:16:02.\n",
      "Batch 2,100  of  3,937.    Elapsed: 0:16:07.\n",
      "Batch 2,110  of  3,937.    Elapsed: 0:16:11.\n",
      "Batch 2,120  of  3,937.    Elapsed: 0:16:16.\n",
      "Batch 2,130  of  3,937.    Elapsed: 0:16:21.\n",
      "Batch 2,140  of  3,937.    Elapsed: 0:16:25.\n",
      "Batch 2,150  of  3,937.    Elapsed: 0:16:30.\n",
      "Batch 2,160  of  3,937.    Elapsed: 0:16:34.\n",
      "Batch 2,170  of  3,937.    Elapsed: 0:16:39.\n",
      "Batch 2,180  of  3,937.    Elapsed: 0:16:44.\n",
      "Batch 2,190  of  3,937.    Elapsed: 0:16:48.\n",
      "Batch 2,200  of  3,937.    Elapsed: 0:16:53.\n",
      "Batch 2,210  of  3,937.    Elapsed: 0:16:57.\n",
      "Batch 2,220  of  3,937.    Elapsed: 0:17:02.\n",
      "Batch 2,230  of  3,937.    Elapsed: 0:17:07.\n",
      "Batch 2,240  of  3,937.    Elapsed: 0:17:11.\n",
      "Batch 2,250  of  3,937.    Elapsed: 0:17:16.\n",
      "Batch 2,260  of  3,937.    Elapsed: 0:17:20.\n",
      "Batch 2,270  of  3,937.    Elapsed: 0:17:25.\n",
      "Batch 2,280  of  3,937.    Elapsed: 0:17:29.\n",
      "Batch 2,290  of  3,937.    Elapsed: 0:17:34.\n",
      "Batch 2,300  of  3,937.    Elapsed: 0:17:39.\n",
      "Batch 2,310  of  3,937.    Elapsed: 0:17:43.\n",
      "Batch 2,320  of  3,937.    Elapsed: 0:17:48.\n",
      "Batch 2,330  of  3,937.    Elapsed: 0:17:52.\n",
      "Batch 2,340  of  3,937.    Elapsed: 0:17:57.\n",
      "Batch 2,350  of  3,937.    Elapsed: 0:18:02.\n",
      "Batch 2,360  of  3,937.    Elapsed: 0:18:06.\n",
      "Batch 2,370  of  3,937.    Elapsed: 0:18:11.\n",
      "Batch 2,380  of  3,937.    Elapsed: 0:18:15.\n",
      "Batch 2,390  of  3,937.    Elapsed: 0:18:20.\n",
      "Batch 2,400  of  3,937.    Elapsed: 0:18:25.\n",
      "Batch 2,410  of  3,937.    Elapsed: 0:18:29.\n",
      "Batch 2,420  of  3,937.    Elapsed: 0:18:34.\n",
      "Batch 2,430  of  3,937.    Elapsed: 0:18:38.\n",
      "Batch 2,440  of  3,937.    Elapsed: 0:18:43.\n",
      "Batch 2,450  of  3,937.    Elapsed: 0:18:48.\n",
      "Batch 2,460  of  3,937.    Elapsed: 0:18:52.\n",
      "Batch 2,470  of  3,937.    Elapsed: 0:18:57.\n",
      "Batch 2,480  of  3,937.    Elapsed: 0:19:01.\n",
      "Batch 2,490  of  3,937.    Elapsed: 0:19:06.\n",
      "Batch 2,500  of  3,937.    Elapsed: 0:19:11.\n",
      "Batch 2,510  of  3,937.    Elapsed: 0:19:15.\n",
      "Batch 2,520  of  3,937.    Elapsed: 0:19:20.\n",
      "Batch 2,530  of  3,937.    Elapsed: 0:19:24.\n",
      "Batch 2,540  of  3,937.    Elapsed: 0:19:29.\n",
      "Batch 2,550  of  3,937.    Elapsed: 0:19:34.\n",
      "Batch 2,560  of  3,937.    Elapsed: 0:19:38.\n",
      "Batch 2,570  of  3,937.    Elapsed: 0:19:43.\n",
      "Batch 2,580  of  3,937.    Elapsed: 0:19:47.\n",
      "Batch 2,590  of  3,937.    Elapsed: 0:19:52.\n",
      "Batch 2,600  of  3,937.    Elapsed: 0:19:57.\n",
      "Batch 2,610  of  3,937.    Elapsed: 0:20:01.\n",
      "Batch 2,620  of  3,937.    Elapsed: 0:20:06.\n",
      "Batch 2,630  of  3,937.    Elapsed: 0:20:10.\n",
      "Batch 2,640  of  3,937.    Elapsed: 0:20:15.\n",
      "Batch 2,650  of  3,937.    Elapsed: 0:20:19.\n",
      "Batch 2,660  of  3,937.    Elapsed: 0:20:24.\n",
      "Batch 2,670  of  3,937.    Elapsed: 0:20:29.\n",
      "Batch 2,680  of  3,937.    Elapsed: 0:20:33.\n",
      "Batch 2,690  of  3,937.    Elapsed: 0:20:38.\n",
      "Batch 2,700  of  3,937.    Elapsed: 0:20:42.\n",
      "Batch 2,710  of  3,937.    Elapsed: 0:20:47.\n",
      "Batch 2,720  of  3,937.    Elapsed: 0:20:51.\n",
      "Batch 2,730  of  3,937.    Elapsed: 0:20:56.\n",
      "Batch 2,740  of  3,937.    Elapsed: 0:21:01.\n",
      "Batch 2,750  of  3,937.    Elapsed: 0:21:05.\n",
      "Batch 2,760  of  3,937.    Elapsed: 0:21:10.\n",
      "Batch 2,770  of  3,937.    Elapsed: 0:21:14.\n",
      "Batch 2,780  of  3,937.    Elapsed: 0:21:19.\n",
      "Batch 2,790  of  3,937.    Elapsed: 0:21:24.\n",
      "Batch 2,800  of  3,937.    Elapsed: 0:21:28.\n",
      "Batch 2,810  of  3,937.    Elapsed: 0:21:33.\n",
      "Batch 2,820  of  3,937.    Elapsed: 0:21:37.\n",
      "Batch 2,830  of  3,937.    Elapsed: 0:21:42.\n",
      "Batch 2,840  of  3,937.    Elapsed: 0:21:46.\n",
      "Batch 2,850  of  3,937.    Elapsed: 0:21:51.\n",
      "Batch 2,860  of  3,937.    Elapsed: 0:21:56.\n",
      "Batch 2,870  of  3,937.    Elapsed: 0:22:00.\n",
      "Batch 2,880  of  3,937.    Elapsed: 0:22:05.\n",
      "Batch 2,890  of  3,937.    Elapsed: 0:22:09.\n",
      "Batch 2,900  of  3,937.    Elapsed: 0:22:14.\n",
      "Batch 2,910  of  3,937.    Elapsed: 0:22:19.\n",
      "Batch 2,920  of  3,937.    Elapsed: 0:22:23.\n",
      "Batch 2,930  of  3,937.    Elapsed: 0:22:28.\n",
      "Batch 2,940  of  3,937.    Elapsed: 0:22:32.\n",
      "Batch 2,950  of  3,937.    Elapsed: 0:22:37.\n",
      "Batch 2,960  of  3,937.    Elapsed: 0:22:42.\n",
      "Batch 2,970  of  3,937.    Elapsed: 0:22:46.\n",
      "Batch 2,980  of  3,937.    Elapsed: 0:22:51.\n",
      "Batch 2,990  of  3,937.    Elapsed: 0:22:55.\n",
      "Batch 3,000  of  3,937.    Elapsed: 0:23:00.\n",
      "Batch 3,010  of  3,937.    Elapsed: 0:23:05.\n",
      "Batch 3,020  of  3,937.    Elapsed: 0:23:09.\n",
      "Batch 3,030  of  3,937.    Elapsed: 0:23:14.\n",
      "Batch 3,040  of  3,937.    Elapsed: 0:23:18.\n",
      "Batch 3,050  of  3,937.    Elapsed: 0:23:23.\n",
      "Batch 3,060  of  3,937.    Elapsed: 0:23:28.\n",
      "Batch 3,070  of  3,937.    Elapsed: 0:23:32.\n",
      "Batch 3,080  of  3,937.    Elapsed: 0:23:37.\n",
      "Batch 3,090  of  3,937.    Elapsed: 0:23:41.\n",
      "Batch 3,100  of  3,937.    Elapsed: 0:23:46.\n",
      "Batch 3,110  of  3,937.    Elapsed: 0:23:51.\n",
      "Batch 3,120  of  3,937.    Elapsed: 0:23:55.\n",
      "Batch 3,130  of  3,937.    Elapsed: 0:24:00.\n",
      "Batch 3,140  of  3,937.    Elapsed: 0:24:04.\n",
      "Batch 3,150  of  3,937.    Elapsed: 0:24:09.\n",
      "Batch 3,160  of  3,937.    Elapsed: 0:24:13.\n",
      "Batch 3,170  of  3,937.    Elapsed: 0:24:18.\n",
      "Batch 3,180  of  3,937.    Elapsed: 0:24:23.\n",
      "Batch 3,190  of  3,937.    Elapsed: 0:24:27.\n",
      "Batch 3,200  of  3,937.    Elapsed: 0:24:32.\n",
      "Batch 3,210  of  3,937.    Elapsed: 0:24:36.\n",
      "Batch 3,220  of  3,937.    Elapsed: 0:24:41.\n",
      "Batch 3,230  of  3,937.    Elapsed: 0:24:46.\n",
      "Batch 3,240  of  3,937.    Elapsed: 0:24:50.\n",
      "Batch 3,250  of  3,937.    Elapsed: 0:24:55.\n",
      "Batch 3,260  of  3,937.    Elapsed: 0:24:59.\n",
      "Batch 3,270  of  3,937.    Elapsed: 0:25:04.\n",
      "Batch 3,280  of  3,937.    Elapsed: 0:25:08.\n",
      "Batch 3,290  of  3,937.    Elapsed: 0:25:13.\n",
      "Batch 3,300  of  3,937.    Elapsed: 0:25:18.\n",
      "Batch 3,310  of  3,937.    Elapsed: 0:25:22.\n",
      "Batch 3,320  of  3,937.    Elapsed: 0:25:27.\n",
      "Batch 3,330  of  3,937.    Elapsed: 0:25:31.\n",
      "Batch 3,340  of  3,937.    Elapsed: 0:25:36.\n",
      "Batch 3,350  of  3,937.    Elapsed: 0:25:40.\n",
      "Batch 3,360  of  3,937.    Elapsed: 0:25:45.\n",
      "Batch 3,370  of  3,937.    Elapsed: 0:25:50.\n",
      "Batch 3,380  of  3,937.    Elapsed: 0:25:54.\n",
      "Batch 3,390  of  3,937.    Elapsed: 0:25:59.\n",
      "Batch 3,400  of  3,937.    Elapsed: 0:26:03.\n",
      "Batch 3,410  of  3,937.    Elapsed: 0:26:08.\n",
      "Batch 3,420  of  3,937.    Elapsed: 0:26:13.\n",
      "Batch 3,430  of  3,937.    Elapsed: 0:26:17.\n",
      "Batch 3,440  of  3,937.    Elapsed: 0:26:22.\n",
      "Batch 3,450  of  3,937.    Elapsed: 0:26:26.\n",
      "Batch 3,460  of  3,937.    Elapsed: 0:26:31.\n",
      "Batch 3,470  of  3,937.    Elapsed: 0:26:35.\n",
      "Batch 3,480  of  3,937.    Elapsed: 0:26:40.\n",
      "Batch 3,490  of  3,937.    Elapsed: 0:26:45.\n",
      "Batch 3,500  of  3,937.    Elapsed: 0:26:49.\n",
      "Batch 3,510  of  3,937.    Elapsed: 0:26:54.\n",
      "Batch 3,520  of  3,937.    Elapsed: 0:26:58.\n",
      "Batch 3,530  of  3,937.    Elapsed: 0:27:03.\n",
      "Batch 3,540  of  3,937.    Elapsed: 0:27:08.\n",
      "Batch 3,550  of  3,937.    Elapsed: 0:27:12.\n",
      "Batch 3,560  of  3,937.    Elapsed: 0:27:17.\n",
      "Batch 3,570  of  3,937.    Elapsed: 0:27:21.\n",
      "Batch 3,580  of  3,937.    Elapsed: 0:27:26.\n",
      "Batch 3,590  of  3,937.    Elapsed: 0:27:31.\n",
      "Batch 3,600  of  3,937.    Elapsed: 0:27:35.\n",
      "Batch 3,610  of  3,937.    Elapsed: 0:27:40.\n",
      "Batch 3,620  of  3,937.    Elapsed: 0:27:44.\n",
      "Batch 3,630  of  3,937.    Elapsed: 0:27:49.\n",
      "Batch 3,640  of  3,937.    Elapsed: 0:27:53.\n",
      "Batch 3,650  of  3,937.    Elapsed: 0:27:58.\n",
      "Batch 3,660  of  3,937.    Elapsed: 0:28:03.\n",
      "Batch 3,670  of  3,937.    Elapsed: 0:28:07.\n",
      "Batch 3,680  of  3,937.    Elapsed: 0:28:12.\n",
      "Batch 3,690  of  3,937.    Elapsed: 0:28:16.\n",
      "Batch 3,700  of  3,937.    Elapsed: 0:28:21.\n",
      "Batch 3,710  of  3,937.    Elapsed: 0:28:26.\n",
      "Batch 3,720  of  3,937.    Elapsed: 0:28:30.\n",
      "Batch 3,730  of  3,937.    Elapsed: 0:28:35.\n",
      "Batch 3,740  of  3,937.    Elapsed: 0:28:39.\n",
      "Batch 3,750  of  3,937.    Elapsed: 0:28:44.\n",
      "Batch 3,760  of  3,937.    Elapsed: 0:28:49.\n",
      "Batch 3,770  of  3,937.    Elapsed: 0:28:53.\n",
      "Batch 3,780  of  3,937.    Elapsed: 0:28:58.\n",
      "Batch 3,790  of  3,937.    Elapsed: 0:29:02.\n",
      "Batch 3,800  of  3,937.    Elapsed: 0:29:07.\n",
      "Batch 3,810  of  3,937.    Elapsed: 0:29:11.\n",
      "Batch 3,820  of  3,937.    Elapsed: 0:29:16.\n",
      "Batch 3,830  of  3,937.    Elapsed: 0:29:21.\n",
      "Batch 3,840  of  3,937.    Elapsed: 0:29:25.\n",
      "Batch 3,850  of  3,937.    Elapsed: 0:29:30.\n",
      "Batch 3,860  of  3,937.    Elapsed: 0:29:34.\n",
      "Batch 3,870  of  3,937.    Elapsed: 0:29:39.\n",
      "Batch 3,880  of  3,937.    Elapsed: 0:29:44.\n",
      "Batch 3,890  of  3,937.    Elapsed: 0:29:48.\n",
      "Batch 3,900  of  3,937.    Elapsed: 0:29:53.\n",
      "Batch 3,910  of  3,937.    Elapsed: 0:29:57.\n",
      "Batch 3,920  of  3,937.    Elapsed: 0:30:02.\n",
      "Batch 3,930  of  3,937.    Elapsed: 0:30:07.\n",
      "Average training loss: 0.03\n",
      "Training epoch took: 0:30:10\n",
      "======== Epoch 2 / 4 ========\n",
      "Batch    10  of  3,937.    Elapsed: 0:00:05.\n",
      "Batch    20  of  3,937.    Elapsed: 0:00:09.\n",
      "Batch    30  of  3,937.    Elapsed: 0:00:14.\n",
      "Batch    40  of  3,937.    Elapsed: 0:00:18.\n",
      "Batch    50  of  3,937.    Elapsed: 0:00:23.\n",
      "Batch    60  of  3,937.    Elapsed: 0:00:28.\n",
      "Batch    70  of  3,937.    Elapsed: 0:00:32.\n",
      "Batch    80  of  3,937.    Elapsed: 0:00:37.\n",
      "Batch    90  of  3,937.    Elapsed: 0:00:41.\n",
      "Batch   100  of  3,937.    Elapsed: 0:00:46.\n",
      "Batch   110  of  3,937.    Elapsed: 0:00:50.\n",
      "Batch   120  of  3,937.    Elapsed: 0:00:55.\n",
      "Batch   130  of  3,937.    Elapsed: 0:01:00.\n",
      "Batch   140  of  3,937.    Elapsed: 0:01:04.\n",
      "Batch   150  of  3,937.    Elapsed: 0:01:09.\n",
      "Batch   160  of  3,937.    Elapsed: 0:01:13.\n",
      "Batch   170  of  3,937.    Elapsed: 0:01:18.\n",
      "Batch   180  of  3,937.    Elapsed: 0:01:23.\n",
      "Batch   190  of  3,937.    Elapsed: 0:01:27.\n",
      "Batch   200  of  3,937.    Elapsed: 0:01:32.\n",
      "Batch   210  of  3,937.    Elapsed: 0:01:36.\n",
      "Batch   220  of  3,937.    Elapsed: 0:01:41.\n",
      "Batch   230  of  3,937.    Elapsed: 0:01:46.\n",
      "Batch   240  of  3,937.    Elapsed: 0:01:50.\n",
      "Batch   250  of  3,937.    Elapsed: 0:01:55.\n",
      "Batch   260  of  3,937.    Elapsed: 0:01:59.\n",
      "Batch   270  of  3,937.    Elapsed: 0:02:04.\n",
      "Batch   280  of  3,937.    Elapsed: 0:02:08.\n",
      "Batch   290  of  3,937.    Elapsed: 0:02:13.\n",
      "Batch   300  of  3,937.    Elapsed: 0:02:18.\n",
      "Batch   310  of  3,937.    Elapsed: 0:02:22.\n",
      "Batch   320  of  3,937.    Elapsed: 0:02:27.\n",
      "Batch   330  of  3,937.    Elapsed: 0:02:31.\n",
      "Batch   340  of  3,937.    Elapsed: 0:02:36.\n",
      "Batch   350  of  3,937.    Elapsed: 0:02:41.\n",
      "Batch   360  of  3,937.    Elapsed: 0:02:45.\n",
      "Batch   370  of  3,937.    Elapsed: 0:02:50.\n",
      "Batch   380  of  3,937.    Elapsed: 0:02:54.\n",
      "Batch   390  of  3,937.    Elapsed: 0:02:59.\n",
      "Batch   400  of  3,937.    Elapsed: 0:03:04.\n",
      "Batch   410  of  3,937.    Elapsed: 0:03:08.\n",
      "Batch   420  of  3,937.    Elapsed: 0:03:13.\n",
      "Batch   430  of  3,937.    Elapsed: 0:03:17.\n",
      "Batch   440  of  3,937.    Elapsed: 0:03:22.\n",
      "Batch   450  of  3,937.    Elapsed: 0:03:27.\n",
      "Batch   460  of  3,937.    Elapsed: 0:03:31.\n",
      "Batch   470  of  3,937.    Elapsed: 0:03:36.\n",
      "Batch   480  of  3,937.    Elapsed: 0:03:40.\n",
      "Batch   490  of  3,937.    Elapsed: 0:03:45.\n",
      "Batch   500  of  3,937.    Elapsed: 0:03:50.\n",
      "Batch   510  of  3,937.    Elapsed: 0:03:54.\n",
      "Batch   520  of  3,937.    Elapsed: 0:03:59.\n",
      "Batch   530  of  3,937.    Elapsed: 0:04:03.\n",
      "Batch   540  of  3,937.    Elapsed: 0:04:08.\n",
      "Batch   550  of  3,937.    Elapsed: 0:04:13.\n",
      "Batch   560  of  3,937.    Elapsed: 0:04:17.\n",
      "Batch   570  of  3,937.    Elapsed: 0:04:22.\n",
      "Batch   580  of  3,937.    Elapsed: 0:04:26.\n",
      "Batch   590  of  3,937.    Elapsed: 0:04:31.\n",
      "Batch   600  of  3,937.    Elapsed: 0:04:35.\n",
      "Batch   610  of  3,937.    Elapsed: 0:04:40.\n",
      "Batch   620  of  3,937.    Elapsed: 0:04:45.\n",
      "Batch   630  of  3,937.    Elapsed: 0:04:49.\n",
      "Batch   640  of  3,937.    Elapsed: 0:04:54.\n",
      "Batch   650  of  3,937.    Elapsed: 0:04:59.\n",
      "Batch   660  of  3,937.    Elapsed: 0:05:03.\n",
      "Batch   670  of  3,937.    Elapsed: 0:05:08.\n",
      "Batch   680  of  3,937.    Elapsed: 0:05:12.\n",
      "Batch   690  of  3,937.    Elapsed: 0:05:17.\n",
      "Batch   700  of  3,937.    Elapsed: 0:05:21.\n",
      "Batch   710  of  3,937.    Elapsed: 0:05:26.\n",
      "Batch   720  of  3,937.    Elapsed: 0:05:31.\n",
      "Batch   730  of  3,937.    Elapsed: 0:05:35.\n",
      "Batch   740  of  3,937.    Elapsed: 0:05:40.\n",
      "Batch   750  of  3,937.    Elapsed: 0:05:44.\n",
      "Batch   760  of  3,937.    Elapsed: 0:05:49.\n",
      "Batch   770  of  3,937.    Elapsed: 0:05:54.\n",
      "Batch   780  of  3,937.    Elapsed: 0:05:58.\n",
      "Batch   790  of  3,937.    Elapsed: 0:06:03.\n",
      "Batch   800  of  3,937.    Elapsed: 0:06:07.\n",
      "Batch   810  of  3,937.    Elapsed: 0:06:12.\n",
      "Batch   820  of  3,937.    Elapsed: 0:06:17.\n",
      "Batch   830  of  3,937.    Elapsed: 0:06:21.\n",
      "Batch   840  of  3,937.    Elapsed: 0:06:26.\n",
      "Batch   850  of  3,937.    Elapsed: 0:06:30.\n",
      "Batch   860  of  3,937.    Elapsed: 0:06:35.\n",
      "Batch   870  of  3,937.    Elapsed: 0:06:39.\n",
      "Batch   880  of  3,937.    Elapsed: 0:06:44.\n",
      "Batch   890  of  3,937.    Elapsed: 0:06:49.\n",
      "Batch   900  of  3,937.    Elapsed: 0:06:53.\n",
      "Batch   910  of  3,937.    Elapsed: 0:06:58.\n",
      "Batch   920  of  3,937.    Elapsed: 0:07:02.\n",
      "Batch   930  of  3,937.    Elapsed: 0:07:07.\n",
      "Batch   940  of  3,937.    Elapsed: 0:07:12.\n",
      "Batch   950  of  3,937.    Elapsed: 0:07:16.\n",
      "Batch   960  of  3,937.    Elapsed: 0:07:21.\n",
      "Batch   970  of  3,937.    Elapsed: 0:07:25.\n",
      "Batch   980  of  3,937.    Elapsed: 0:07:30.\n",
      "Batch   990  of  3,937.    Elapsed: 0:07:34.\n",
      "Batch 1,000  of  3,937.    Elapsed: 0:07:39.\n",
      "Batch 1,010  of  3,937.    Elapsed: 0:07:44.\n",
      "Batch 1,020  of  3,937.    Elapsed: 0:07:48.\n",
      "Batch 1,030  of  3,937.    Elapsed: 0:07:53.\n",
      "Batch 1,040  of  3,937.    Elapsed: 0:07:57.\n",
      "Batch 1,050  of  3,937.    Elapsed: 0:08:02.\n",
      "Batch 1,060  of  3,937.    Elapsed: 0:08:07.\n",
      "Batch 1,070  of  3,937.    Elapsed: 0:08:11.\n",
      "Batch 1,080  of  3,937.    Elapsed: 0:08:16.\n",
      "Batch 1,090  of  3,937.    Elapsed: 0:08:20.\n",
      "Batch 1,100  of  3,937.    Elapsed: 0:08:25.\n",
      "Batch 1,110  of  3,937.    Elapsed: 0:08:29.\n",
      "Batch 1,120  of  3,937.    Elapsed: 0:08:34.\n",
      "Batch 1,130  of  3,937.    Elapsed: 0:08:39.\n",
      "Batch 1,140  of  3,937.    Elapsed: 0:08:43.\n",
      "Batch 1,150  of  3,937.    Elapsed: 0:08:48.\n",
      "Batch 1,160  of  3,937.    Elapsed: 0:08:52.\n",
      "Batch 1,170  of  3,937.    Elapsed: 0:08:57.\n",
      "Batch 1,180  of  3,937.    Elapsed: 0:09:02.\n",
      "Batch 1,190  of  3,937.    Elapsed: 0:09:06.\n",
      "Batch 1,200  of  3,937.    Elapsed: 0:09:11.\n",
      "Batch 1,210  of  3,937.    Elapsed: 0:09:15.\n",
      "Batch 1,220  of  3,937.    Elapsed: 0:09:20.\n",
      "Batch 1,230  of  3,937.    Elapsed: 0:09:24.\n",
      "Batch 1,240  of  3,937.    Elapsed: 0:09:29.\n",
      "Batch 1,250  of  3,937.    Elapsed: 0:09:34.\n",
      "Batch 1,260  of  3,937.    Elapsed: 0:09:38.\n",
      "Batch 1,270  of  3,937.    Elapsed: 0:09:43.\n",
      "Batch 1,280  of  3,937.    Elapsed: 0:09:47.\n",
      "Batch 1,290  of  3,937.    Elapsed: 0:09:52.\n",
      "Batch 1,300  of  3,937.    Elapsed: 0:09:57.\n",
      "Batch 1,310  of  3,937.    Elapsed: 0:10:01.\n",
      "Batch 1,320  of  3,937.    Elapsed: 0:10:06.\n",
      "Batch 1,330  of  3,937.    Elapsed: 0:10:10.\n",
      "Batch 1,340  of  3,937.    Elapsed: 0:10:15.\n",
      "Batch 1,350  of  3,937.    Elapsed: 0:10:19.\n",
      "Batch 1,360  of  3,937.    Elapsed: 0:10:24.\n",
      "Batch 1,370  of  3,937.    Elapsed: 0:10:29.\n",
      "Batch 1,380  of  3,937.    Elapsed: 0:10:33.\n",
      "Batch 1,390  of  3,937.    Elapsed: 0:10:38.\n",
      "Batch 1,400  of  3,937.    Elapsed: 0:10:42.\n",
      "Batch 1,410  of  3,937.    Elapsed: 0:10:47.\n",
      "Batch 1,420  of  3,937.    Elapsed: 0:10:52.\n",
      "Batch 1,430  of  3,937.    Elapsed: 0:10:56.\n",
      "Batch 1,440  of  3,937.    Elapsed: 0:11:01.\n",
      "Batch 1,450  of  3,937.    Elapsed: 0:11:05.\n",
      "Batch 1,460  of  3,937.    Elapsed: 0:11:10.\n",
      "Batch 1,470  of  3,937.    Elapsed: 0:11:14.\n",
      "Batch 1,480  of  3,937.    Elapsed: 0:11:19.\n",
      "Batch 1,490  of  3,937.    Elapsed: 0:11:24.\n",
      "Batch 1,500  of  3,937.    Elapsed: 0:11:28.\n",
      "Batch 1,510  of  3,937.    Elapsed: 0:11:33.\n",
      "Batch 1,520  of  3,937.    Elapsed: 0:11:37.\n",
      "Batch 1,530  of  3,937.    Elapsed: 0:11:42.\n",
      "Batch 1,540  of  3,937.    Elapsed: 0:11:47.\n",
      "Batch 1,550  of  3,937.    Elapsed: 0:11:51.\n",
      "Batch 1,560  of  3,937.    Elapsed: 0:11:56.\n",
      "Batch 1,570  of  3,937.    Elapsed: 0:12:00.\n",
      "Batch 1,580  of  3,937.    Elapsed: 0:12:05.\n",
      "Batch 1,590  of  3,937.    Elapsed: 0:12:10.\n",
      "Batch 1,600  of  3,937.    Elapsed: 0:12:14.\n",
      "Batch 1,610  of  3,937.    Elapsed: 0:12:19.\n",
      "Batch 1,620  of  3,937.    Elapsed: 0:12:23.\n",
      "Batch 1,630  of  3,937.    Elapsed: 0:12:28.\n",
      "Batch 1,640  of  3,937.    Elapsed: 0:12:32.\n",
      "Batch 1,650  of  3,937.    Elapsed: 0:12:37.\n",
      "Batch 1,660  of  3,937.    Elapsed: 0:12:42.\n",
      "Batch 1,670  of  3,937.    Elapsed: 0:12:46.\n",
      "Batch 1,680  of  3,937.    Elapsed: 0:12:51.\n",
      "Batch 1,690  of  3,937.    Elapsed: 0:12:55.\n",
      "Batch 1,700  of  3,937.    Elapsed: 0:13:00.\n",
      "Batch 1,710  of  3,937.    Elapsed: 0:13:04.\n",
      "Batch 1,720  of  3,937.    Elapsed: 0:13:09.\n",
      "Batch 1,730  of  3,937.    Elapsed: 0:13:14.\n",
      "Batch 1,740  of  3,937.    Elapsed: 0:13:18.\n",
      "Batch 1,750  of  3,937.    Elapsed: 0:13:23.\n",
      "Batch 1,760  of  3,937.    Elapsed: 0:13:27.\n",
      "Batch 1,770  of  3,937.    Elapsed: 0:13:32.\n",
      "Batch 1,780  of  3,937.    Elapsed: 0:13:36.\n",
      "Batch 1,790  of  3,937.    Elapsed: 0:13:41.\n",
      "Batch 1,800  of  3,937.    Elapsed: 0:13:46.\n",
      "Batch 1,810  of  3,937.    Elapsed: 0:13:50.\n",
      "Batch 1,820  of  3,937.    Elapsed: 0:13:55.\n",
      "Batch 1,830  of  3,937.    Elapsed: 0:13:59.\n",
      "Batch 1,840  of  3,937.    Elapsed: 0:14:04.\n",
      "Batch 1,850  of  3,937.    Elapsed: 0:14:08.\n",
      "Batch 1,860  of  3,937.    Elapsed: 0:14:13.\n",
      "Batch 1,870  of  3,937.    Elapsed: 0:14:18.\n",
      "Batch 1,880  of  3,937.    Elapsed: 0:14:22.\n",
      "Batch 1,890  of  3,937.    Elapsed: 0:14:27.\n",
      "Batch 1,900  of  3,937.    Elapsed: 0:14:31.\n",
      "Batch 1,910  of  3,937.    Elapsed: 0:14:36.\n",
      "Batch 1,920  of  3,937.    Elapsed: 0:14:41.\n",
      "Batch 1,930  of  3,937.    Elapsed: 0:14:45.\n",
      "Batch 1,940  of  3,937.    Elapsed: 0:14:50.\n",
      "Batch 1,950  of  3,937.    Elapsed: 0:14:54.\n",
      "Batch 1,960  of  3,937.    Elapsed: 0:14:59.\n",
      "Batch 1,970  of  3,937.    Elapsed: 0:15:03.\n",
      "Batch 1,980  of  3,937.    Elapsed: 0:15:08.\n",
      "Batch 1,990  of  3,937.    Elapsed: 0:15:13.\n",
      "Batch 2,000  of  3,937.    Elapsed: 0:15:17.\n",
      "Batch 2,010  of  3,937.    Elapsed: 0:15:22.\n",
      "Batch 2,020  of  3,937.    Elapsed: 0:15:26.\n",
      "Batch 2,030  of  3,937.    Elapsed: 0:15:31.\n",
      "Batch 2,040  of  3,937.    Elapsed: 0:15:36.\n",
      "Batch 2,050  of  3,937.    Elapsed: 0:15:40.\n",
      "Batch 2,060  of  3,937.    Elapsed: 0:15:45.\n",
      "Batch 2,070  of  3,937.    Elapsed: 0:15:49.\n",
      "Batch 2,080  of  3,937.    Elapsed: 0:15:54.\n",
      "Batch 2,090  of  3,937.    Elapsed: 0:15:58.\n",
      "Batch 2,100  of  3,937.    Elapsed: 0:16:03.\n",
      "Batch 2,110  of  3,937.    Elapsed: 0:16:08.\n",
      "Batch 2,120  of  3,937.    Elapsed: 0:16:12.\n",
      "Batch 2,130  of  3,937.    Elapsed: 0:16:17.\n",
      "Batch 2,140  of  3,937.    Elapsed: 0:16:21.\n",
      "Batch 2,150  of  3,937.    Elapsed: 0:16:26.\n",
      "Batch 2,160  of  3,937.    Elapsed: 0:16:31.\n",
      "Batch 2,170  of  3,937.    Elapsed: 0:16:35.\n",
      "Batch 2,180  of  3,937.    Elapsed: 0:16:40.\n",
      "Batch 2,190  of  3,937.    Elapsed: 0:16:44.\n",
      "Batch 2,200  of  3,937.    Elapsed: 0:16:49.\n",
      "Batch 2,210  of  3,937.    Elapsed: 0:16:53.\n",
      "Batch 2,220  of  3,937.    Elapsed: 0:16:58.\n",
      "Batch 2,230  of  3,937.    Elapsed: 0:17:03.\n",
      "Batch 2,240  of  3,937.    Elapsed: 0:17:07.\n",
      "Batch 2,250  of  3,937.    Elapsed: 0:17:12.\n",
      "Batch 2,260  of  3,937.    Elapsed: 0:17:16.\n",
      "Batch 2,270  of  3,937.    Elapsed: 0:17:21.\n",
      "Batch 2,280  of  3,937.    Elapsed: 0:17:26.\n",
      "Batch 2,290  of  3,937.    Elapsed: 0:17:30.\n",
      "Batch 2,300  of  3,937.    Elapsed: 0:17:35.\n",
      "Batch 2,310  of  3,937.    Elapsed: 0:17:39.\n",
      "Batch 2,320  of  3,937.    Elapsed: 0:17:44.\n",
      "Batch 2,330  of  3,937.    Elapsed: 0:17:48.\n",
      "Batch 2,340  of  3,937.    Elapsed: 0:17:53.\n",
      "Batch 2,350  of  3,937.    Elapsed: 0:17:58.\n",
      "Batch 2,360  of  3,937.    Elapsed: 0:18:02.\n",
      "Batch 2,370  of  3,937.    Elapsed: 0:18:07.\n",
      "Batch 2,380  of  3,937.    Elapsed: 0:18:11.\n",
      "Batch 2,390  of  3,937.    Elapsed: 0:18:16.\n",
      "Batch 2,400  of  3,937.    Elapsed: 0:18:21.\n",
      "Batch 2,410  of  3,937.    Elapsed: 0:18:25.\n",
      "Batch 2,420  of  3,937.    Elapsed: 0:18:30.\n",
      "Batch 2,430  of  3,937.    Elapsed: 0:18:34.\n",
      "Batch 2,440  of  3,937.    Elapsed: 0:18:39.\n",
      "Batch 2,450  of  3,937.    Elapsed: 0:18:43.\n",
      "Batch 2,460  of  3,937.    Elapsed: 0:18:48.\n",
      "Batch 2,470  of  3,937.    Elapsed: 0:18:53.\n",
      "Batch 2,480  of  3,937.    Elapsed: 0:18:57.\n",
      "Batch 2,490  of  3,937.    Elapsed: 0:19:02.\n",
      "Batch 2,500  of  3,937.    Elapsed: 0:19:06.\n",
      "Batch 2,510  of  3,937.    Elapsed: 0:19:11.\n",
      "Batch 2,520  of  3,937.    Elapsed: 0:19:16.\n",
      "Batch 2,530  of  3,937.    Elapsed: 0:19:20.\n",
      "Batch 2,540  of  3,937.    Elapsed: 0:19:25.\n",
      "Batch 2,550  of  3,937.    Elapsed: 0:19:29.\n",
      "Batch 2,560  of  3,937.    Elapsed: 0:19:34.\n",
      "Batch 2,570  of  3,937.    Elapsed: 0:19:38.\n",
      "Batch 2,580  of  3,937.    Elapsed: 0:19:43.\n",
      "Batch 2,590  of  3,937.    Elapsed: 0:19:48.\n",
      "Batch 2,600  of  3,937.    Elapsed: 0:19:52.\n",
      "Batch 2,610  of  3,937.    Elapsed: 0:19:57.\n",
      "Batch 2,620  of  3,937.    Elapsed: 0:20:01.\n",
      "Batch 2,630  of  3,937.    Elapsed: 0:20:06.\n",
      "Batch 2,640  of  3,937.    Elapsed: 0:20:11.\n",
      "Batch 2,650  of  3,937.    Elapsed: 0:20:15.\n",
      "Batch 2,660  of  3,937.    Elapsed: 0:20:20.\n",
      "Batch 2,670  of  3,937.    Elapsed: 0:20:24.\n",
      "Batch 2,680  of  3,937.    Elapsed: 0:20:29.\n",
      "Batch 2,690  of  3,937.    Elapsed: 0:20:33.\n",
      "Batch 2,700  of  3,937.    Elapsed: 0:20:38.\n",
      "Batch 2,710  of  3,937.    Elapsed: 0:20:43.\n",
      "Batch 2,720  of  3,937.    Elapsed: 0:20:47.\n",
      "Batch 2,730  of  3,937.    Elapsed: 0:20:52.\n",
      "Batch 2,740  of  3,937.    Elapsed: 0:20:56.\n",
      "Batch 2,750  of  3,937.    Elapsed: 0:21:01.\n",
      "Batch 2,760  of  3,937.    Elapsed: 0:21:06.\n",
      "Batch 2,770  of  3,937.    Elapsed: 0:21:10.\n",
      "Batch 2,780  of  3,937.    Elapsed: 0:21:15.\n",
      "Batch 2,790  of  3,937.    Elapsed: 0:21:19.\n",
      "Batch 2,800  of  3,937.    Elapsed: 0:21:24.\n",
      "Batch 2,810  of  3,937.    Elapsed: 0:21:28.\n",
      "Batch 2,820  of  3,937.    Elapsed: 0:21:33.\n",
      "Batch 2,830  of  3,937.    Elapsed: 0:21:38.\n",
      "Batch 2,840  of  3,937.    Elapsed: 0:21:42.\n",
      "Batch 2,850  of  3,937.    Elapsed: 0:21:47.\n",
      "Batch 2,860  of  3,937.    Elapsed: 0:21:51.\n",
      "Batch 2,870  of  3,937.    Elapsed: 0:21:56.\n",
      "Batch 2,880  of  3,937.    Elapsed: 0:22:00.\n",
      "Batch 2,890  of  3,937.    Elapsed: 0:22:05.\n",
      "Batch 2,900  of  3,937.    Elapsed: 0:22:10.\n",
      "Batch 2,910  of  3,937.    Elapsed: 0:22:14.\n",
      "Batch 2,920  of  3,937.    Elapsed: 0:22:19.\n",
      "Batch 2,930  of  3,937.    Elapsed: 0:22:23.\n",
      "Batch 2,940  of  3,937.    Elapsed: 0:22:28.\n",
      "Batch 2,950  of  3,937.    Elapsed: 0:22:33.\n",
      "Batch 2,960  of  3,937.    Elapsed: 0:22:37.\n",
      "Batch 2,970  of  3,937.    Elapsed: 0:22:42.\n",
      "Batch 2,980  of  3,937.    Elapsed: 0:22:46.\n",
      "Batch 2,990  of  3,937.    Elapsed: 0:22:51.\n",
      "Batch 3,000  of  3,937.    Elapsed: 0:22:56.\n",
      "Batch 3,010  of  3,937.    Elapsed: 0:23:00.\n",
      "Batch 3,020  of  3,937.    Elapsed: 0:23:05.\n",
      "Batch 3,030  of  3,937.    Elapsed: 0:23:09.\n",
      "Batch 3,040  of  3,937.    Elapsed: 0:23:14.\n",
      "Batch 3,050  of  3,937.    Elapsed: 0:23:18.\n",
      "Batch 3,060  of  3,937.    Elapsed: 0:23:23.\n",
      "Batch 3,070  of  3,937.    Elapsed: 0:23:28.\n",
      "Batch 3,080  of  3,937.    Elapsed: 0:23:32.\n",
      "Batch 3,090  of  3,937.    Elapsed: 0:23:37.\n",
      "Batch 3,100  of  3,937.    Elapsed: 0:23:41.\n",
      "Batch 3,110  of  3,937.    Elapsed: 0:23:46.\n",
      "Batch 3,120  of  3,937.    Elapsed: 0:23:51.\n",
      "Batch 3,130  of  3,937.    Elapsed: 0:23:55.\n",
      "Batch 3,140  of  3,937.    Elapsed: 0:24:00.\n",
      "Batch 3,150  of  3,937.    Elapsed: 0:24:04.\n",
      "Batch 3,160  of  3,937.    Elapsed: 0:24:09.\n",
      "Batch 3,170  of  3,937.    Elapsed: 0:24:13.\n",
      "Batch 3,180  of  3,937.    Elapsed: 0:24:18.\n",
      "Batch 3,190  of  3,937.    Elapsed: 0:24:23.\n",
      "Batch 3,200  of  3,937.    Elapsed: 0:24:27.\n",
      "Batch 3,210  of  3,937.    Elapsed: 0:24:32.\n",
      "Batch 3,220  of  3,937.    Elapsed: 0:24:36.\n",
      "Batch 3,230  of  3,937.    Elapsed: 0:24:41.\n",
      "Batch 3,240  of  3,937.    Elapsed: 0:24:45.\n",
      "Batch 3,250  of  3,937.    Elapsed: 0:24:50.\n",
      "Batch 3,260  of  3,937.    Elapsed: 0:24:55.\n",
      "Batch 3,270  of  3,937.    Elapsed: 0:24:59.\n",
      "Batch 3,280  of  3,937.    Elapsed: 0:25:04.\n",
      "Batch 3,290  of  3,937.    Elapsed: 0:25:08.\n",
      "Batch 3,300  of  3,937.    Elapsed: 0:25:13.\n",
      "Batch 3,310  of  3,937.    Elapsed: 0:25:17.\n",
      "Batch 3,320  of  3,937.    Elapsed: 0:25:22.\n",
      "Batch 3,330  of  3,937.    Elapsed: 0:25:27.\n",
      "Batch 3,340  of  3,937.    Elapsed: 0:25:31.\n",
      "Batch 3,350  of  3,937.    Elapsed: 0:25:36.\n",
      "Batch 3,360  of  3,937.    Elapsed: 0:25:40.\n",
      "Batch 3,370  of  3,937.    Elapsed: 0:25:45.\n",
      "Batch 3,380  of  3,937.    Elapsed: 0:25:50.\n",
      "Batch 3,390  of  3,937.    Elapsed: 0:25:54.\n",
      "Batch 3,400  of  3,937.    Elapsed: 0:25:59.\n",
      "Batch 3,410  of  3,937.    Elapsed: 0:26:03.\n",
      "Batch 3,420  of  3,937.    Elapsed: 0:26:08.\n",
      "Batch 3,430  of  3,937.    Elapsed: 0:26:12.\n",
      "Batch 3,440  of  3,937.    Elapsed: 0:26:17.\n",
      "Batch 3,450  of  3,937.    Elapsed: 0:26:22.\n",
      "Batch 3,460  of  3,937.    Elapsed: 0:26:26.\n",
      "Batch 3,470  of  3,937.    Elapsed: 0:26:31.\n",
      "Batch 3,480  of  3,937.    Elapsed: 0:26:35.\n",
      "Batch 3,490  of  3,937.    Elapsed: 0:26:40.\n",
      "Batch 3,500  of  3,937.    Elapsed: 0:26:44.\n",
      "Batch 3,510  of  3,937.    Elapsed: 0:26:49.\n",
      "Batch 3,520  of  3,937.    Elapsed: 0:26:54.\n",
      "Batch 3,530  of  3,937.    Elapsed: 0:26:58.\n",
      "Batch 3,540  of  3,937.    Elapsed: 0:27:03.\n",
      "Batch 3,550  of  3,937.    Elapsed: 0:27:07.\n",
      "Batch 3,560  of  3,937.    Elapsed: 0:27:12.\n",
      "Batch 3,570  of  3,937.    Elapsed: 0:27:16.\n",
      "Batch 3,580  of  3,937.    Elapsed: 0:27:21.\n",
      "Batch 3,590  of  3,937.    Elapsed: 0:27:26.\n",
      "Batch 3,600  of  3,937.    Elapsed: 0:27:30.\n",
      "Batch 3,610  of  3,937.    Elapsed: 0:27:35.\n",
      "Batch 3,620  of  3,937.    Elapsed: 0:27:39.\n",
      "Batch 3,630  of  3,937.    Elapsed: 0:27:44.\n",
      "Batch 3,640  of  3,937.    Elapsed: 0:27:49.\n",
      "Batch 3,650  of  3,937.    Elapsed: 0:27:53.\n",
      "Batch 3,660  of  3,937.    Elapsed: 0:27:58.\n",
      "Batch 3,670  of  3,937.    Elapsed: 0:28:02.\n",
      "Batch 3,680  of  3,937.    Elapsed: 0:28:07.\n",
      "Batch 3,690  of  3,937.    Elapsed: 0:28:12.\n",
      "Batch 3,700  of  3,937.    Elapsed: 0:28:16.\n",
      "Batch 3,710  of  3,937.    Elapsed: 0:28:21.\n",
      "Batch 3,720  of  3,937.    Elapsed: 0:28:25.\n",
      "Batch 3,730  of  3,937.    Elapsed: 0:28:30.\n",
      "Batch 3,740  of  3,937.    Elapsed: 0:28:34.\n",
      "Batch 3,750  of  3,937.    Elapsed: 0:28:39.\n",
      "Batch 3,760  of  3,937.    Elapsed: 0:28:44.\n",
      "Batch 3,770  of  3,937.    Elapsed: 0:28:48.\n",
      "Batch 3,780  of  3,937.    Elapsed: 0:28:53.\n",
      "Batch 3,790  of  3,937.    Elapsed: 0:28:57.\n",
      "Batch 3,800  of  3,937.    Elapsed: 0:29:02.\n",
      "Batch 3,810  of  3,937.    Elapsed: 0:29:07.\n",
      "Batch 3,820  of  3,937.    Elapsed: 0:29:11.\n",
      "Batch 3,830  of  3,937.    Elapsed: 0:29:16.\n",
      "Batch 3,840  of  3,937.    Elapsed: 0:29:20.\n",
      "Batch 3,850  of  3,937.    Elapsed: 0:29:25.\n",
      "Batch 3,860  of  3,937.    Elapsed: 0:29:29.\n",
      "Batch 3,870  of  3,937.    Elapsed: 0:29:34.\n",
      "Batch 3,880  of  3,937.    Elapsed: 0:29:39.\n",
      "Batch 3,890  of  3,937.    Elapsed: 0:29:43.\n",
      "Batch 3,900  of  3,937.    Elapsed: 0:29:48.\n",
      "Batch 3,910  of  3,937.    Elapsed: 0:29:52.\n",
      "Batch 3,920  of  3,937.    Elapsed: 0:29:57.\n",
      "Batch 3,930  of  3,937.    Elapsed: 0:30:02.\n",
      "Average training loss: 0.01\n",
      "Training epoch took: 0:30:05\n",
      "======== Epoch 3 / 4 ========\n",
      "Batch    10  of  3,937.    Elapsed: 0:00:05.\n",
      "Batch    20  of  3,937.    Elapsed: 0:00:09.\n",
      "Batch    30  of  3,937.    Elapsed: 0:00:14.\n",
      "Batch    40  of  3,937.    Elapsed: 0:00:18.\n",
      "Batch    50  of  3,937.    Elapsed: 0:00:23.\n",
      "Batch    60  of  3,937.    Elapsed: 0:00:28.\n",
      "Batch    70  of  3,937.    Elapsed: 0:00:32.\n",
      "Batch    80  of  3,937.    Elapsed: 0:00:37.\n",
      "Batch    90  of  3,937.    Elapsed: 0:00:41.\n",
      "Batch   100  of  3,937.    Elapsed: 0:00:46.\n",
      "Batch   110  of  3,937.    Elapsed: 0:00:50.\n",
      "Batch   120  of  3,937.    Elapsed: 0:00:55.\n",
      "Batch   130  of  3,937.    Elapsed: 0:01:00.\n",
      "Batch   140  of  3,937.    Elapsed: 0:01:04.\n",
      "Batch   150  of  3,937.    Elapsed: 0:01:09.\n",
      "Batch   160  of  3,937.    Elapsed: 0:01:13.\n",
      "Batch   170  of  3,937.    Elapsed: 0:01:18.\n",
      "Batch   180  of  3,937.    Elapsed: 0:01:23.\n",
      "Batch   190  of  3,937.    Elapsed: 0:01:27.\n",
      "Batch   200  of  3,937.    Elapsed: 0:01:32.\n",
      "Batch   210  of  3,937.    Elapsed: 0:01:36.\n",
      "Batch   220  of  3,937.    Elapsed: 0:01:41.\n",
      "Batch   230  of  3,937.    Elapsed: 0:01:45.\n",
      "Batch   240  of  3,937.    Elapsed: 0:01:50.\n",
      "Batch   250  of  3,937.    Elapsed: 0:01:55.\n",
      "Batch   260  of  3,937.    Elapsed: 0:01:59.\n",
      "Batch   270  of  3,937.    Elapsed: 0:02:04.\n",
      "Batch   280  of  3,937.    Elapsed: 0:02:08.\n",
      "Batch   290  of  3,937.    Elapsed: 0:02:13.\n",
      "Batch   300  of  3,937.    Elapsed: 0:02:18.\n",
      "Batch   310  of  3,937.    Elapsed: 0:02:22.\n",
      "Batch   320  of  3,937.    Elapsed: 0:02:27.\n",
      "Batch   330  of  3,937.    Elapsed: 0:02:31.\n",
      "Batch   340  of  3,937.    Elapsed: 0:02:36.\n",
      "Batch   350  of  3,937.    Elapsed: 0:02:40.\n",
      "Batch   360  of  3,937.    Elapsed: 0:02:45.\n",
      "Batch   370  of  3,937.    Elapsed: 0:02:50.\n",
      "Batch   380  of  3,937.    Elapsed: 0:02:54.\n",
      "Batch   390  of  3,937.    Elapsed: 0:02:59.\n",
      "Batch   400  of  3,937.    Elapsed: 0:03:03.\n",
      "Batch   410  of  3,937.    Elapsed: 0:03:08.\n",
      "Batch   420  of  3,937.    Elapsed: 0:03:13.\n",
      "Batch   430  of  3,937.    Elapsed: 0:03:17.\n",
      "Batch   440  of  3,937.    Elapsed: 0:03:22.\n",
      "Batch   450  of  3,937.    Elapsed: 0:03:26.\n",
      "Batch   460  of  3,937.    Elapsed: 0:03:31.\n",
      "Batch   470  of  3,937.    Elapsed: 0:03:35.\n",
      "Batch   480  of  3,937.    Elapsed: 0:03:40.\n",
      "Batch   490  of  3,937.    Elapsed: 0:03:45.\n",
      "Batch   500  of  3,937.    Elapsed: 0:03:49.\n",
      "Batch   510  of  3,937.    Elapsed: 0:03:54.\n",
      "Batch   520  of  3,937.    Elapsed: 0:03:58.\n",
      "Batch   530  of  3,937.    Elapsed: 0:04:03.\n",
      "Batch   540  of  3,937.    Elapsed: 0:04:08.\n",
      "Batch   550  of  3,937.    Elapsed: 0:04:12.\n",
      "Batch   560  of  3,937.    Elapsed: 0:04:17.\n",
      "Batch   570  of  3,937.    Elapsed: 0:04:21.\n",
      "Batch   580  of  3,937.    Elapsed: 0:04:26.\n",
      "Batch   590  of  3,937.    Elapsed: 0:04:30.\n",
      "Batch   600  of  3,937.    Elapsed: 0:04:35.\n",
      "Batch   610  of  3,937.    Elapsed: 0:04:40.\n",
      "Batch   620  of  3,937.    Elapsed: 0:04:44.\n",
      "Batch   630  of  3,937.    Elapsed: 0:04:49.\n",
      "Batch   640  of  3,937.    Elapsed: 0:04:53.\n",
      "Batch   650  of  3,937.    Elapsed: 0:04:58.\n",
      "Batch   660  of  3,937.    Elapsed: 0:05:03.\n",
      "Batch   670  of  3,937.    Elapsed: 0:05:07.\n",
      "Batch   680  of  3,937.    Elapsed: 0:05:12.\n",
      "Batch   690  of  3,937.    Elapsed: 0:05:16.\n",
      "Batch   700  of  3,937.    Elapsed: 0:05:21.\n",
      "Batch   710  of  3,937.    Elapsed: 0:05:26.\n",
      "Batch   720  of  3,937.    Elapsed: 0:05:30.\n",
      "Batch   730  of  3,937.    Elapsed: 0:05:35.\n",
      "Batch   740  of  3,937.    Elapsed: 0:05:39.\n",
      "Batch   750  of  3,937.    Elapsed: 0:05:44.\n",
      "Batch   760  of  3,937.    Elapsed: 0:05:48.\n",
      "Batch   770  of  3,937.    Elapsed: 0:05:53.\n",
      "Batch   780  of  3,937.    Elapsed: 0:05:58.\n",
      "Batch   790  of  3,937.    Elapsed: 0:06:02.\n",
      "Batch   800  of  3,937.    Elapsed: 0:06:07.\n",
      "Batch   810  of  3,937.    Elapsed: 0:06:11.\n",
      "Batch   820  of  3,937.    Elapsed: 0:06:16.\n",
      "Batch   830  of  3,937.    Elapsed: 0:06:21.\n",
      "Batch   840  of  3,937.    Elapsed: 0:06:25.\n",
      "Batch   850  of  3,937.    Elapsed: 0:06:30.\n",
      "Batch   860  of  3,937.    Elapsed: 0:06:34.\n",
      "Batch   870  of  3,937.    Elapsed: 0:06:39.\n",
      "Batch   880  of  3,937.    Elapsed: 0:06:43.\n",
      "Batch   890  of  3,937.    Elapsed: 0:06:48.\n",
      "Batch   900  of  3,937.    Elapsed: 0:06:53.\n",
      "Batch   910  of  3,937.    Elapsed: 0:06:57.\n",
      "Batch   920  of  3,937.    Elapsed: 0:07:02.\n",
      "Batch   930  of  3,937.    Elapsed: 0:07:06.\n",
      "Batch   940  of  3,937.    Elapsed: 0:07:11.\n",
      "Batch   950  of  3,937.    Elapsed: 0:07:16.\n",
      "Batch   960  of  3,937.    Elapsed: 0:07:20.\n",
      "Batch   970  of  3,937.    Elapsed: 0:07:25.\n",
      "Batch   980  of  3,937.    Elapsed: 0:07:29.\n",
      "Batch   990  of  3,937.    Elapsed: 0:07:34.\n",
      "Batch 1,000  of  3,937.    Elapsed: 0:07:38.\n",
      "Batch 1,010  of  3,937.    Elapsed: 0:07:43.\n",
      "Batch 1,020  of  3,937.    Elapsed: 0:07:48.\n",
      "Batch 1,030  of  3,937.    Elapsed: 0:07:52.\n",
      "Batch 1,040  of  3,937.    Elapsed: 0:07:57.\n",
      "Batch 1,050  of  3,937.    Elapsed: 0:08:01.\n",
      "Batch 1,060  of  3,937.    Elapsed: 0:08:06.\n",
      "Batch 1,070  of  3,937.    Elapsed: 0:08:11.\n",
      "Batch 1,080  of  3,937.    Elapsed: 0:08:15.\n",
      "Batch 1,090  of  3,937.    Elapsed: 0:08:20.\n",
      "Batch 1,100  of  3,937.    Elapsed: 0:08:24.\n",
      "Batch 1,110  of  3,937.    Elapsed: 0:08:29.\n",
      "Batch 1,120  of  3,937.    Elapsed: 0:08:33.\n",
      "Batch 1,130  of  3,937.    Elapsed: 0:08:38.\n",
      "Batch 1,140  of  3,937.    Elapsed: 0:08:43.\n",
      "Batch 1,150  of  3,937.    Elapsed: 0:08:47.\n",
      "Batch 1,160  of  3,937.    Elapsed: 0:08:52.\n",
      "Batch 1,170  of  3,937.    Elapsed: 0:08:56.\n",
      "Batch 1,180  of  3,937.    Elapsed: 0:09:01.\n",
      "Batch 1,190  of  3,937.    Elapsed: 0:09:06.\n",
      "Batch 1,200  of  3,937.    Elapsed: 0:09:10.\n",
      "Batch 1,210  of  3,937.    Elapsed: 0:09:15.\n",
      "Batch 1,220  of  3,937.    Elapsed: 0:09:19.\n",
      "Batch 1,230  of  3,937.    Elapsed: 0:09:24.\n",
      "Batch 1,240  of  3,937.    Elapsed: 0:09:28.\n",
      "Batch 1,250  of  3,937.    Elapsed: 0:09:33.\n",
      "Batch 1,260  of  3,937.    Elapsed: 0:09:38.\n",
      "Batch 1,270  of  3,937.    Elapsed: 0:09:42.\n",
      "Batch 1,280  of  3,937.    Elapsed: 0:09:47.\n",
      "Batch 1,290  of  3,937.    Elapsed: 0:09:51.\n",
      "Batch 1,300  of  3,937.    Elapsed: 0:09:56.\n",
      "Batch 1,310  of  3,937.    Elapsed: 0:10:01.\n",
      "Batch 1,320  of  3,937.    Elapsed: 0:10:05.\n",
      "Batch 1,330  of  3,937.    Elapsed: 0:10:10.\n",
      "Batch 1,340  of  3,937.    Elapsed: 0:10:14.\n",
      "Batch 1,350  of  3,937.    Elapsed: 0:10:19.\n",
      "Batch 1,360  of  3,937.    Elapsed: 0:10:24.\n",
      "Batch 1,370  of  3,937.    Elapsed: 0:10:28.\n",
      "Batch 1,380  of  3,937.    Elapsed: 0:10:33.\n",
      "Batch 1,390  of  3,937.    Elapsed: 0:10:37.\n",
      "Batch 1,400  of  3,937.    Elapsed: 0:10:42.\n",
      "Batch 1,410  of  3,937.    Elapsed: 0:10:47.\n",
      "Batch 1,420  of  3,937.    Elapsed: 0:10:51.\n",
      "Batch 1,430  of  3,937.    Elapsed: 0:10:56.\n",
      "Batch 1,440  of  3,937.    Elapsed: 0:11:00.\n",
      "Batch 1,450  of  3,937.    Elapsed: 0:11:05.\n",
      "Batch 1,460  of  3,937.    Elapsed: 0:11:09.\n",
      "Batch 1,470  of  3,937.    Elapsed: 0:11:14.\n",
      "Batch 1,480  of  3,937.    Elapsed: 0:11:19.\n",
      "Batch 1,490  of  3,937.    Elapsed: 0:11:23.\n",
      "Batch 1,500  of  3,937.    Elapsed: 0:11:28.\n",
      "Batch 1,510  of  3,937.    Elapsed: 0:11:32.\n",
      "Batch 1,520  of  3,937.    Elapsed: 0:11:37.\n",
      "Batch 1,530  of  3,937.    Elapsed: 0:11:41.\n",
      "Batch 1,540  of  3,937.    Elapsed: 0:11:46.\n",
      "Batch 1,550  of  3,937.    Elapsed: 0:11:51.\n",
      "Batch 1,560  of  3,937.    Elapsed: 0:11:55.\n",
      "Batch 1,570  of  3,937.    Elapsed: 0:12:00.\n",
      "Batch 1,580  of  3,937.    Elapsed: 0:12:04.\n",
      "Batch 1,590  of  3,937.    Elapsed: 0:12:09.\n",
      "Batch 1,600  of  3,937.    Elapsed: 0:12:13.\n",
      "Batch 1,610  of  3,937.    Elapsed: 0:12:18.\n",
      "Batch 1,620  of  3,937.    Elapsed: 0:12:23.\n",
      "Batch 1,630  of  3,937.    Elapsed: 0:12:27.\n",
      "Batch 1,640  of  3,937.    Elapsed: 0:12:32.\n",
      "Batch 1,650  of  3,937.    Elapsed: 0:12:36.\n",
      "Batch 1,660  of  3,937.    Elapsed: 0:12:41.\n",
      "Batch 1,670  of  3,937.    Elapsed: 0:12:45.\n",
      "Batch 1,680  of  3,937.    Elapsed: 0:12:50.\n",
      "Batch 1,690  of  3,937.    Elapsed: 0:12:55.\n",
      "Batch 1,700  of  3,937.    Elapsed: 0:12:59.\n",
      "Batch 1,710  of  3,937.    Elapsed: 0:13:04.\n",
      "Batch 1,720  of  3,937.    Elapsed: 0:13:08.\n",
      "Batch 1,730  of  3,937.    Elapsed: 0:13:13.\n",
      "Batch 1,740  of  3,937.    Elapsed: 0:13:18.\n",
      "Batch 1,750  of  3,937.    Elapsed: 0:13:22.\n",
      "Batch 1,760  of  3,937.    Elapsed: 0:13:27.\n",
      "Batch 1,770  of  3,937.    Elapsed: 0:13:31.\n",
      "Batch 1,780  of  3,937.    Elapsed: 0:13:36.\n",
      "Batch 1,790  of  3,937.    Elapsed: 0:13:40.\n",
      "Batch 1,800  of  3,937.    Elapsed: 0:13:45.\n",
      "Batch 1,810  of  3,937.    Elapsed: 0:13:50.\n",
      "Batch 1,820  of  3,937.    Elapsed: 0:13:54.\n",
      "Batch 1,830  of  3,937.    Elapsed: 0:13:59.\n",
      "Batch 1,840  of  3,937.    Elapsed: 0:14:03.\n",
      "Batch 1,850  of  3,937.    Elapsed: 0:14:08.\n",
      "Batch 1,860  of  3,937.    Elapsed: 0:14:13.\n",
      "Batch 1,870  of  3,937.    Elapsed: 0:14:17.\n",
      "Batch 1,880  of  3,937.    Elapsed: 0:14:22.\n",
      "Batch 1,890  of  3,937.    Elapsed: 0:14:26.\n",
      "Batch 1,900  of  3,937.    Elapsed: 0:14:31.\n",
      "Batch 1,910  of  3,937.    Elapsed: 0:14:35.\n",
      "Batch 1,920  of  3,937.    Elapsed: 0:14:40.\n",
      "Batch 1,930  of  3,937.    Elapsed: 0:14:45.\n",
      "Batch 1,940  of  3,937.    Elapsed: 0:14:49.\n",
      "Batch 1,950  of  3,937.    Elapsed: 0:14:54.\n",
      "Batch 1,960  of  3,937.    Elapsed: 0:14:58.\n",
      "Batch 1,970  of  3,937.    Elapsed: 0:15:03.\n",
      "Batch 1,980  of  3,937.    Elapsed: 0:15:08.\n",
      "Batch 1,990  of  3,937.    Elapsed: 0:15:12.\n",
      "Batch 2,000  of  3,937.    Elapsed: 0:15:17.\n",
      "Batch 2,010  of  3,937.    Elapsed: 0:15:21.\n",
      "Batch 2,020  of  3,937.    Elapsed: 0:15:26.\n",
      "Batch 2,030  of  3,937.    Elapsed: 0:15:31.\n",
      "Batch 2,040  of  3,937.    Elapsed: 0:15:35.\n",
      "Batch 2,050  of  3,937.    Elapsed: 0:15:40.\n",
      "Batch 2,060  of  3,937.    Elapsed: 0:15:44.\n",
      "Batch 2,070  of  3,937.    Elapsed: 0:15:49.\n",
      "Batch 2,080  of  3,937.    Elapsed: 0:15:53.\n",
      "Batch 2,090  of  3,937.    Elapsed: 0:15:58.\n",
      "Batch 2,100  of  3,937.    Elapsed: 0:16:03.\n",
      "Batch 2,110  of  3,937.    Elapsed: 0:16:07.\n",
      "Batch 2,120  of  3,937.    Elapsed: 0:16:12.\n",
      "Batch 2,130  of  3,937.    Elapsed: 0:16:16.\n",
      "Batch 2,140  of  3,937.    Elapsed: 0:16:21.\n",
      "Batch 2,150  of  3,937.    Elapsed: 0:16:25.\n",
      "Batch 2,160  of  3,937.    Elapsed: 0:16:30.\n",
      "Batch 2,170  of  3,937.    Elapsed: 0:16:34.\n",
      "Batch 2,180  of  3,937.    Elapsed: 0:16:39.\n",
      "Batch 2,190  of  3,937.    Elapsed: 0:16:44.\n",
      "Batch 2,200  of  3,937.    Elapsed: 0:16:48.\n",
      "Batch 2,210  of  3,937.    Elapsed: 0:16:53.\n",
      "Batch 2,220  of  3,937.    Elapsed: 0:16:57.\n",
      "Batch 2,230  of  3,937.    Elapsed: 0:17:02.\n",
      "Batch 2,240  of  3,937.    Elapsed: 0:17:06.\n",
      "Batch 2,250  of  3,937.    Elapsed: 0:17:11.\n",
      "Batch 2,260  of  3,937.    Elapsed: 0:17:16.\n",
      "Batch 2,270  of  3,937.    Elapsed: 0:17:20.\n",
      "Batch 2,280  of  3,937.    Elapsed: 0:17:25.\n",
      "Batch 2,290  of  3,937.    Elapsed: 0:17:29.\n",
      "Batch 2,300  of  3,937.    Elapsed: 0:17:34.\n",
      "Batch 2,310  of  3,937.    Elapsed: 0:17:39.\n",
      "Batch 2,320  of  3,937.    Elapsed: 0:17:43.\n",
      "Batch 2,330  of  3,937.    Elapsed: 0:17:48.\n",
      "Batch 2,340  of  3,937.    Elapsed: 0:17:52.\n",
      "Batch 2,350  of  3,937.    Elapsed: 0:17:57.\n",
      "Batch 2,360  of  3,937.    Elapsed: 0:18:01.\n",
      "Batch 2,370  of  3,937.    Elapsed: 0:18:06.\n",
      "Batch 2,380  of  3,937.    Elapsed: 0:18:11.\n",
      "Batch 2,390  of  3,937.    Elapsed: 0:18:15.\n",
      "Batch 2,400  of  3,937.    Elapsed: 0:18:20.\n",
      "Batch 2,410  of  3,937.    Elapsed: 0:18:24.\n",
      "Batch 2,420  of  3,937.    Elapsed: 0:18:29.\n",
      "Batch 2,430  of  3,937.    Elapsed: 0:18:33.\n",
      "Batch 2,440  of  3,937.    Elapsed: 0:18:38.\n",
      "Batch 2,450  of  3,937.    Elapsed: 0:18:43.\n",
      "Batch 2,460  of  3,937.    Elapsed: 0:18:47.\n",
      "Batch 2,470  of  3,937.    Elapsed: 0:18:52.\n",
      "Batch 2,480  of  3,937.    Elapsed: 0:18:56.\n",
      "Batch 2,490  of  3,937.    Elapsed: 0:19:01.\n",
      "Batch 2,500  of  3,937.    Elapsed: 0:19:05.\n",
      "Batch 2,510  of  3,937.    Elapsed: 0:19:10.\n",
      "Batch 2,520  of  3,937.    Elapsed: 0:19:15.\n",
      "Batch 2,530  of  3,937.    Elapsed: 0:19:19.\n",
      "Batch 2,540  of  3,937.    Elapsed: 0:19:24.\n",
      "Batch 2,550  of  3,937.    Elapsed: 0:19:28.\n",
      "Batch 2,560  of  3,937.    Elapsed: 0:19:33.\n",
      "Batch 2,570  of  3,937.    Elapsed: 0:19:37.\n",
      "Batch 2,580  of  3,937.    Elapsed: 0:19:42.\n",
      "Batch 2,590  of  3,937.    Elapsed: 0:19:47.\n",
      "Batch 2,600  of  3,937.    Elapsed: 0:19:51.\n",
      "Batch 2,610  of  3,937.    Elapsed: 0:19:56.\n",
      "Batch 2,620  of  3,937.    Elapsed: 0:20:00.\n",
      "Batch 2,630  of  3,937.    Elapsed: 0:20:05.\n",
      "Batch 2,640  of  3,937.    Elapsed: 0:20:09.\n",
      "Batch 2,650  of  3,937.    Elapsed: 0:20:14.\n",
      "Batch 2,660  of  3,937.    Elapsed: 0:20:19.\n",
      "Batch 2,670  of  3,937.    Elapsed: 0:20:23.\n",
      "Batch 2,680  of  3,937.    Elapsed: 0:20:28.\n",
      "Batch 2,690  of  3,937.    Elapsed: 0:20:32.\n",
      "Batch 2,700  of  3,937.    Elapsed: 0:20:37.\n",
      "Batch 2,710  of  3,937.    Elapsed: 0:20:41.\n",
      "Batch 2,720  of  3,937.    Elapsed: 0:20:46.\n",
      "Batch 2,730  of  3,937.    Elapsed: 0:20:51.\n",
      "Batch 2,740  of  3,937.    Elapsed: 0:20:55.\n",
      "Batch 2,750  of  3,937.    Elapsed: 0:21:00.\n",
      "Batch 2,760  of  3,937.    Elapsed: 0:21:04.\n",
      "Batch 2,770  of  3,937.    Elapsed: 0:21:09.\n",
      "Batch 2,780  of  3,937.    Elapsed: 0:21:13.\n",
      "Batch 2,790  of  3,937.    Elapsed: 0:21:18.\n",
      "Batch 2,800  of  3,937.    Elapsed: 0:21:23.\n",
      "Batch 2,810  of  3,937.    Elapsed: 0:21:27.\n",
      "Batch 2,820  of  3,937.    Elapsed: 0:21:32.\n",
      "Batch 2,830  of  3,937.    Elapsed: 0:21:36.\n",
      "Batch 2,840  of  3,937.    Elapsed: 0:21:41.\n",
      "Batch 2,850  of  3,937.    Elapsed: 0:21:45.\n",
      "Batch 2,860  of  3,937.    Elapsed: 0:21:50.\n",
      "Batch 2,870  of  3,937.    Elapsed: 0:21:55.\n",
      "Batch 2,880  of  3,937.    Elapsed: 0:21:59.\n",
      "Batch 2,890  of  3,937.    Elapsed: 0:22:04.\n",
      "Batch 2,900  of  3,937.    Elapsed: 0:22:08.\n",
      "Batch 2,910  of  3,937.    Elapsed: 0:22:13.\n",
      "Batch 2,920  of  3,937.    Elapsed: 0:22:17.\n",
      "Batch 2,930  of  3,937.    Elapsed: 0:22:22.\n",
      "Batch 2,940  of  3,937.    Elapsed: 0:22:26.\n",
      "Batch 2,950  of  3,937.    Elapsed: 0:22:31.\n",
      "Batch 2,960  of  3,937.    Elapsed: 0:22:36.\n",
      "Batch 2,970  of  3,937.    Elapsed: 0:22:40.\n",
      "Batch 2,980  of  3,937.    Elapsed: 0:22:45.\n",
      "Batch 2,990  of  3,937.    Elapsed: 0:22:49.\n",
      "Batch 3,000  of  3,937.    Elapsed: 0:22:54.\n",
      "Batch 3,010  of  3,937.    Elapsed: 0:22:58.\n",
      "Batch 3,020  of  3,937.    Elapsed: 0:23:03.\n",
      "Batch 3,030  of  3,937.    Elapsed: 0:23:08.\n",
      "Batch 3,040  of  3,937.    Elapsed: 0:23:12.\n",
      "Batch 3,050  of  3,937.    Elapsed: 0:23:17.\n",
      "Batch 3,060  of  3,937.    Elapsed: 0:23:21.\n",
      "Batch 3,070  of  3,937.    Elapsed: 0:23:26.\n",
      "Batch 3,080  of  3,937.    Elapsed: 0:23:30.\n",
      "Batch 3,090  of  3,937.    Elapsed: 0:23:35.\n",
      "Batch 3,100  of  3,937.    Elapsed: 0:23:40.\n",
      "Batch 3,110  of  3,937.    Elapsed: 0:23:44.\n",
      "Batch 3,120  of  3,937.    Elapsed: 0:23:49.\n",
      "Batch 3,130  of  3,937.    Elapsed: 0:23:53.\n",
      "Batch 3,140  of  3,937.    Elapsed: 0:23:58.\n",
      "Batch 3,150  of  3,937.    Elapsed: 0:24:02.\n",
      "Batch 3,160  of  3,937.    Elapsed: 0:24:07.\n",
      "Batch 3,170  of  3,937.    Elapsed: 0:24:12.\n",
      "Batch 3,180  of  3,937.    Elapsed: 0:24:16.\n",
      "Batch 3,190  of  3,937.    Elapsed: 0:24:21.\n",
      "Batch 3,200  of  3,937.    Elapsed: 0:24:25.\n",
      "Batch 3,210  of  3,937.    Elapsed: 0:24:30.\n",
      "Batch 3,220  of  3,937.    Elapsed: 0:24:34.\n",
      "Batch 3,230  of  3,937.    Elapsed: 0:24:39.\n",
      "Batch 3,240  of  3,937.    Elapsed: 0:24:44.\n",
      "Batch 3,250  of  3,937.    Elapsed: 0:24:48.\n",
      "Batch 3,260  of  3,937.    Elapsed: 0:24:53.\n",
      "Batch 3,270  of  3,937.    Elapsed: 0:24:57.\n",
      "Batch 3,280  of  3,937.    Elapsed: 0:25:02.\n",
      "Batch 3,290  of  3,937.    Elapsed: 0:25:06.\n",
      "Batch 3,300  of  3,937.    Elapsed: 0:25:11.\n",
      "Batch 3,310  of  3,937.    Elapsed: 0:25:16.\n",
      "Batch 3,320  of  3,937.    Elapsed: 0:25:20.\n",
      "Batch 3,330  of  3,937.    Elapsed: 0:25:25.\n",
      "Batch 3,340  of  3,937.    Elapsed: 0:25:29.\n",
      "Batch 3,350  of  3,937.    Elapsed: 0:25:34.\n",
      "Batch 3,360  of  3,937.    Elapsed: 0:25:39.\n",
      "Batch 3,370  of  3,937.    Elapsed: 0:25:43.\n",
      "Batch 3,380  of  3,937.    Elapsed: 0:25:48.\n",
      "Batch 3,390  of  3,937.    Elapsed: 0:25:52.\n",
      "Batch 3,400  of  3,937.    Elapsed: 0:25:57.\n",
      "Batch 3,410  of  3,937.    Elapsed: 0:26:01.\n",
      "Batch 3,420  of  3,937.    Elapsed: 0:26:06.\n",
      "Batch 3,430  of  3,937.    Elapsed: 0:26:11.\n",
      "Batch 3,440  of  3,937.    Elapsed: 0:26:15.\n",
      "Batch 3,450  of  3,937.    Elapsed: 0:26:20.\n",
      "Batch 3,460  of  3,937.    Elapsed: 0:26:24.\n",
      "Batch 3,470  of  3,937.    Elapsed: 0:26:29.\n",
      "Batch 3,480  of  3,937.    Elapsed: 0:26:33.\n",
      "Batch 3,490  of  3,937.    Elapsed: 0:26:38.\n",
      "Batch 3,500  of  3,937.    Elapsed: 0:26:43.\n",
      "Batch 3,510  of  3,937.    Elapsed: 0:26:47.\n",
      "Batch 3,520  of  3,937.    Elapsed: 0:26:52.\n",
      "Batch 3,530  of  3,937.    Elapsed: 0:26:56.\n",
      "Batch 3,540  of  3,937.    Elapsed: 0:27:01.\n",
      "Batch 3,550  of  3,937.    Elapsed: 0:27:05.\n",
      "Batch 3,560  of  3,937.    Elapsed: 0:27:10.\n",
      "Batch 3,570  of  3,937.    Elapsed: 0:27:15.\n",
      "Batch 3,580  of  3,937.    Elapsed: 0:27:19.\n",
      "Batch 3,590  of  3,937.    Elapsed: 0:27:24.\n",
      "Batch 3,600  of  3,937.    Elapsed: 0:27:28.\n",
      "Batch 3,610  of  3,937.    Elapsed: 0:27:33.\n",
      "Batch 3,620  of  3,937.    Elapsed: 0:27:38.\n",
      "Batch 3,630  of  3,937.    Elapsed: 0:27:42.\n",
      "Batch 3,640  of  3,937.    Elapsed: 0:27:47.\n",
      "Batch 3,650  of  3,937.    Elapsed: 0:27:51.\n",
      "Batch 3,660  of  3,937.    Elapsed: 0:27:56.\n",
      "Batch 3,670  of  3,937.    Elapsed: 0:28:00.\n",
      "Batch 3,680  of  3,937.    Elapsed: 0:28:05.\n",
      "Batch 3,690  of  3,937.    Elapsed: 0:28:10.\n",
      "Batch 3,700  of  3,937.    Elapsed: 0:28:14.\n",
      "Batch 3,710  of  3,937.    Elapsed: 0:28:19.\n",
      "Batch 3,720  of  3,937.    Elapsed: 0:28:23.\n",
      "Batch 3,730  of  3,937.    Elapsed: 0:28:28.\n",
      "Batch 3,740  of  3,937.    Elapsed: 0:28:32.\n",
      "Batch 3,750  of  3,937.    Elapsed: 0:28:37.\n",
      "Batch 3,760  of  3,937.    Elapsed: 0:28:41.\n",
      "Batch 3,770  of  3,937.    Elapsed: 0:28:46.\n",
      "Batch 3,780  of  3,937.    Elapsed: 0:28:51.\n",
      "Batch 3,790  of  3,937.    Elapsed: 0:28:55.\n",
      "Batch 3,800  of  3,937.    Elapsed: 0:29:00.\n",
      "Batch 3,810  of  3,937.    Elapsed: 0:29:04.\n",
      "Batch 3,820  of  3,937.    Elapsed: 0:29:09.\n",
      "Batch 3,830  of  3,937.    Elapsed: 0:29:13.\n",
      "Batch 3,840  of  3,937.    Elapsed: 0:29:18.\n",
      "Batch 3,850  of  3,937.    Elapsed: 0:29:23.\n",
      "Batch 3,860  of  3,937.    Elapsed: 0:29:27.\n",
      "Batch 3,870  of  3,937.    Elapsed: 0:29:32.\n",
      "Batch 3,880  of  3,937.    Elapsed: 0:29:36.\n",
      "Batch 3,890  of  3,937.    Elapsed: 0:29:41.\n",
      "Batch 3,900  of  3,937.    Elapsed: 0:29:45.\n",
      "Batch 3,910  of  3,937.    Elapsed: 0:29:50.\n",
      "Batch 3,920  of  3,937.    Elapsed: 0:29:55.\n",
      "Batch 3,930  of  3,937.    Elapsed: 0:29:59.\n",
      "Average training loss: 0.01\n",
      "Training epoch took: 0:30:02\n",
      "======== Epoch 4 / 4 ========\n",
      "Batch    10  of  3,937.    Elapsed: 0:00:05.\n",
      "Batch    20  of  3,937.    Elapsed: 0:00:09.\n",
      "Batch    30  of  3,937.    Elapsed: 0:00:14.\n",
      "Batch    40  of  3,937.    Elapsed: 0:00:18.\n",
      "Batch    50  of  3,937.    Elapsed: 0:00:23.\n",
      "Batch    60  of  3,937.    Elapsed: 0:00:27.\n",
      "Batch    70  of  3,937.    Elapsed: 0:00:32.\n",
      "Batch    80  of  3,937.    Elapsed: 0:00:37.\n",
      "Batch    90  of  3,937.    Elapsed: 0:00:41.\n",
      "Batch   100  of  3,937.    Elapsed: 0:00:46.\n",
      "Batch   110  of  3,937.    Elapsed: 0:00:50.\n",
      "Batch   120  of  3,937.    Elapsed: 0:00:55.\n",
      "Batch   130  of  3,937.    Elapsed: 0:00:59.\n",
      "Batch   140  of  3,937.    Elapsed: 0:01:04.\n",
      "Batch   150  of  3,937.    Elapsed: 0:01:09.\n",
      "Batch   160  of  3,937.    Elapsed: 0:01:13.\n",
      "Batch   170  of  3,937.    Elapsed: 0:01:18.\n",
      "Batch   180  of  3,937.    Elapsed: 0:01:22.\n",
      "Batch   190  of  3,937.    Elapsed: 0:01:27.\n",
      "Batch   200  of  3,937.    Elapsed: 0:01:31.\n",
      "Batch   210  of  3,937.    Elapsed: 0:01:36.\n",
      "Batch   220  of  3,937.    Elapsed: 0:01:41.\n",
      "Batch   230  of  3,937.    Elapsed: 0:01:45.\n",
      "Batch   240  of  3,937.    Elapsed: 0:01:50.\n",
      "Batch   250  of  3,937.    Elapsed: 0:01:54.\n",
      "Batch   260  of  3,937.    Elapsed: 0:01:59.\n",
      "Batch   270  of  3,937.    Elapsed: 0:02:03.\n",
      "Batch   280  of  3,937.    Elapsed: 0:02:08.\n",
      "Batch   290  of  3,937.    Elapsed: 0:02:13.\n",
      "Batch   300  of  3,937.    Elapsed: 0:02:17.\n",
      "Batch   310  of  3,937.    Elapsed: 0:02:22.\n",
      "Batch   320  of  3,937.    Elapsed: 0:02:26.\n",
      "Batch   330  of  3,937.    Elapsed: 0:02:31.\n",
      "Batch   340  of  3,937.    Elapsed: 0:02:35.\n",
      "Batch   350  of  3,937.    Elapsed: 0:02:40.\n",
      "Batch   360  of  3,937.    Elapsed: 0:02:45.\n",
      "Batch   370  of  3,937.    Elapsed: 0:02:49.\n",
      "Batch   380  of  3,937.    Elapsed: 0:02:54.\n",
      "Batch   390  of  3,937.    Elapsed: 0:02:58.\n",
      "Batch   400  of  3,937.    Elapsed: 0:03:03.\n",
      "Batch   410  of  3,937.    Elapsed: 0:03:07.\n",
      "Batch   420  of  3,937.    Elapsed: 0:03:12.\n",
      "Batch   430  of  3,937.    Elapsed: 0:03:17.\n",
      "Batch   440  of  3,937.    Elapsed: 0:03:21.\n",
      "Batch   450  of  3,937.    Elapsed: 0:03:26.\n",
      "Batch   460  of  3,937.    Elapsed: 0:03:30.\n",
      "Batch   470  of  3,937.    Elapsed: 0:03:35.\n",
      "Batch   480  of  3,937.    Elapsed: 0:03:39.\n",
      "Batch   490  of  3,937.    Elapsed: 0:03:44.\n",
      "Batch   500  of  3,937.    Elapsed: 0:03:49.\n",
      "Batch   510  of  3,937.    Elapsed: 0:03:53.\n",
      "Batch   520  of  3,937.    Elapsed: 0:03:58.\n",
      "Batch   530  of  3,937.    Elapsed: 0:04:02.\n",
      "Batch   540  of  3,937.    Elapsed: 0:04:07.\n",
      "Batch   550  of  3,937.    Elapsed: 0:04:11.\n",
      "Batch   560  of  3,937.    Elapsed: 0:04:16.\n",
      "Batch   570  of  3,937.    Elapsed: 0:04:21.\n",
      "Batch   580  of  3,937.    Elapsed: 0:04:25.\n",
      "Batch   590  of  3,937.    Elapsed: 0:04:30.\n",
      "Batch   600  of  3,937.    Elapsed: 0:04:34.\n",
      "Batch   610  of  3,937.    Elapsed: 0:04:39.\n",
      "Batch   620  of  3,937.    Elapsed: 0:04:43.\n",
      "Batch   630  of  3,937.    Elapsed: 0:04:48.\n",
      "Batch   640  of  3,937.    Elapsed: 0:04:53.\n",
      "Batch   650  of  3,937.    Elapsed: 0:04:57.\n",
      "Batch   660  of  3,937.    Elapsed: 0:05:02.\n",
      "Batch   670  of  3,937.    Elapsed: 0:05:06.\n",
      "Batch   680  of  3,937.    Elapsed: 0:05:11.\n",
      "Batch   690  of  3,937.    Elapsed: 0:05:15.\n",
      "Batch   700  of  3,937.    Elapsed: 0:05:20.\n",
      "Batch   710  of  3,937.    Elapsed: 0:05:25.\n",
      "Batch   720  of  3,937.    Elapsed: 0:05:29.\n",
      "Batch   730  of  3,937.    Elapsed: 0:05:34.\n",
      "Batch   740  of  3,937.    Elapsed: 0:05:38.\n",
      "Batch   750  of  3,937.    Elapsed: 0:05:43.\n",
      "Batch   760  of  3,937.    Elapsed: 0:05:47.\n",
      "Batch   770  of  3,937.    Elapsed: 0:05:52.\n",
      "Batch   780  of  3,937.    Elapsed: 0:05:57.\n",
      "Batch   790  of  3,937.    Elapsed: 0:06:01.\n",
      "Batch   800  of  3,937.    Elapsed: 0:06:06.\n",
      "Batch   810  of  3,937.    Elapsed: 0:06:10.\n",
      "Batch   820  of  3,937.    Elapsed: 0:06:15.\n",
      "Batch   830  of  3,937.    Elapsed: 0:06:19.\n",
      "Batch   840  of  3,937.    Elapsed: 0:06:24.\n",
      "Batch   850  of  3,937.    Elapsed: 0:06:29.\n",
      "Batch   860  of  3,937.    Elapsed: 0:06:33.\n",
      "Batch   870  of  3,937.    Elapsed: 0:06:38.\n",
      "Batch   880  of  3,937.    Elapsed: 0:06:42.\n",
      "Batch   890  of  3,937.    Elapsed: 0:06:47.\n",
      "Batch   900  of  3,937.    Elapsed: 0:06:51.\n",
      "Batch   910  of  3,937.    Elapsed: 0:06:56.\n",
      "Batch   920  of  3,937.    Elapsed: 0:07:01.\n",
      "Batch   930  of  3,937.    Elapsed: 0:07:05.\n",
      "Batch   940  of  3,937.    Elapsed: 0:07:10.\n",
      "Batch   950  of  3,937.    Elapsed: 0:07:14.\n",
      "Batch   960  of  3,937.    Elapsed: 0:07:19.\n",
      "Batch   970  of  3,937.    Elapsed: 0:07:23.\n",
      "Batch   980  of  3,937.    Elapsed: 0:07:28.\n",
      "Batch   990  of  3,937.    Elapsed: 0:07:33.\n",
      "Batch 1,000  of  3,937.    Elapsed: 0:07:37.\n",
      "Batch 1,010  of  3,937.    Elapsed: 0:07:42.\n",
      "Batch 1,020  of  3,937.    Elapsed: 0:07:46.\n",
      "Batch 1,030  of  3,937.    Elapsed: 0:07:51.\n",
      "Batch 1,040  of  3,937.    Elapsed: 0:07:55.\n",
      "Batch 1,050  of  3,937.    Elapsed: 0:08:00.\n",
      "Batch 1,060  of  3,937.    Elapsed: 0:08:05.\n",
      "Batch 1,070  of  3,937.    Elapsed: 0:08:09.\n",
      "Batch 1,080  of  3,937.    Elapsed: 0:08:14.\n",
      "Batch 1,090  of  3,937.    Elapsed: 0:08:18.\n",
      "Batch 1,100  of  3,937.    Elapsed: 0:08:23.\n",
      "Batch 1,110  of  3,937.    Elapsed: 0:08:27.\n",
      "Batch 1,120  of  3,937.    Elapsed: 0:08:32.\n",
      "Batch 1,130  of  3,937.    Elapsed: 0:08:37.\n",
      "Batch 1,140  of  3,937.    Elapsed: 0:08:41.\n",
      "Batch 1,150  of  3,937.    Elapsed: 0:08:46.\n",
      "Batch 1,160  of  3,937.    Elapsed: 0:08:50.\n",
      "Batch 1,170  of  3,937.    Elapsed: 0:08:55.\n",
      "Batch 1,180  of  3,937.    Elapsed: 0:08:59.\n",
      "Batch 1,190  of  3,937.    Elapsed: 0:09:04.\n",
      "Batch 1,200  of  3,937.    Elapsed: 0:09:09.\n",
      "Batch 1,210  of  3,937.    Elapsed: 0:09:13.\n",
      "Batch 1,220  of  3,937.    Elapsed: 0:09:18.\n",
      "Batch 1,230  of  3,937.    Elapsed: 0:09:22.\n",
      "Batch 1,240  of  3,937.    Elapsed: 0:09:27.\n",
      "Batch 1,250  of  3,937.    Elapsed: 0:09:31.\n",
      "Batch 1,260  of  3,937.    Elapsed: 0:09:36.\n",
      "Batch 1,270  of  3,937.    Elapsed: 0:09:41.\n",
      "Batch 1,280  of  3,937.    Elapsed: 0:09:45.\n",
      "Batch 1,290  of  3,937.    Elapsed: 0:09:50.\n",
      "Batch 1,300  of  3,937.    Elapsed: 0:09:54.\n",
      "Batch 1,310  of  3,937.    Elapsed: 0:09:59.\n",
      "Batch 1,320  of  3,937.    Elapsed: 0:10:03.\n",
      "Batch 1,330  of  3,937.    Elapsed: 0:10:08.\n",
      "Batch 1,340  of  3,937.    Elapsed: 0:10:13.\n",
      "Batch 1,350  of  3,937.    Elapsed: 0:10:17.\n",
      "Batch 1,360  of  3,937.    Elapsed: 0:10:22.\n",
      "Batch 1,370  of  3,937.    Elapsed: 0:10:26.\n",
      "Batch 1,380  of  3,937.    Elapsed: 0:10:31.\n",
      "Batch 1,390  of  3,937.    Elapsed: 0:10:35.\n",
      "Batch 1,400  of  3,937.    Elapsed: 0:10:40.\n",
      "Batch 1,410  of  3,937.    Elapsed: 0:10:45.\n",
      "Batch 1,420  of  3,937.    Elapsed: 0:10:49.\n",
      "Batch 1,430  of  3,937.    Elapsed: 0:10:54.\n",
      "Batch 1,440  of  3,937.    Elapsed: 0:10:58.\n",
      "Batch 1,450  of  3,937.    Elapsed: 0:11:03.\n",
      "Batch 1,460  of  3,937.    Elapsed: 0:11:07.\n",
      "Batch 1,470  of  3,937.    Elapsed: 0:11:12.\n",
      "Batch 1,480  of  3,937.    Elapsed: 0:11:17.\n",
      "Batch 1,490  of  3,937.    Elapsed: 0:11:21.\n",
      "Batch 1,500  of  3,937.    Elapsed: 0:11:26.\n",
      "Batch 1,510  of  3,937.    Elapsed: 0:11:30.\n",
      "Batch 1,520  of  3,937.    Elapsed: 0:11:35.\n",
      "Batch 1,530  of  3,937.    Elapsed: 0:11:39.\n",
      "Batch 1,540  of  3,937.    Elapsed: 0:11:44.\n",
      "Batch 1,550  of  3,937.    Elapsed: 0:11:49.\n",
      "Batch 1,560  of  3,937.    Elapsed: 0:11:53.\n",
      "Batch 1,570  of  3,937.    Elapsed: 0:11:58.\n",
      "Batch 1,580  of  3,937.    Elapsed: 0:12:02.\n",
      "Batch 1,590  of  3,937.    Elapsed: 0:12:07.\n",
      "Batch 1,600  of  3,937.    Elapsed: 0:12:11.\n",
      "Batch 1,610  of  3,937.    Elapsed: 0:12:16.\n",
      "Batch 1,620  of  3,937.    Elapsed: 0:12:21.\n",
      "Batch 1,630  of  3,937.    Elapsed: 0:12:25.\n",
      "Batch 1,640  of  3,937.    Elapsed: 0:12:30.\n",
      "Batch 1,650  of  3,937.    Elapsed: 0:12:34.\n",
      "Batch 1,660  of  3,937.    Elapsed: 0:12:39.\n",
      "Batch 1,670  of  3,937.    Elapsed: 0:12:43.\n",
      "Batch 1,680  of  3,937.    Elapsed: 0:12:48.\n",
      "Batch 1,690  of  3,937.    Elapsed: 0:12:53.\n",
      "Batch 1,700  of  3,937.    Elapsed: 0:12:57.\n",
      "Batch 1,710  of  3,937.    Elapsed: 0:13:02.\n",
      "Batch 1,720  of  3,937.    Elapsed: 0:13:06.\n",
      "Batch 1,730  of  3,937.    Elapsed: 0:13:11.\n",
      "Batch 1,740  of  3,937.    Elapsed: 0:13:15.\n",
      "Batch 1,750  of  3,937.    Elapsed: 0:13:20.\n",
      "Batch 1,760  of  3,937.    Elapsed: 0:13:25.\n",
      "Batch 1,770  of  3,937.    Elapsed: 0:13:29.\n",
      "Batch 1,780  of  3,937.    Elapsed: 0:13:34.\n",
      "Batch 1,790  of  3,937.    Elapsed: 0:13:38.\n",
      "Batch 1,800  of  3,937.    Elapsed: 0:13:43.\n",
      "Batch 1,810  of  3,937.    Elapsed: 0:13:47.\n",
      "Batch 1,820  of  3,937.    Elapsed: 0:13:52.\n",
      "Batch 1,830  of  3,937.    Elapsed: 0:13:57.\n",
      "Batch 1,840  of  3,937.    Elapsed: 0:14:01.\n",
      "Batch 1,850  of  3,937.    Elapsed: 0:14:06.\n",
      "Batch 1,860  of  3,937.    Elapsed: 0:14:10.\n",
      "Batch 1,870  of  3,937.    Elapsed: 0:14:15.\n",
      "Batch 1,880  of  3,937.    Elapsed: 0:14:19.\n",
      "Batch 1,890  of  3,937.    Elapsed: 0:14:24.\n",
      "Batch 1,900  of  3,937.    Elapsed: 0:14:28.\n",
      "Batch 1,910  of  3,937.    Elapsed: 0:14:33.\n",
      "Batch 1,920  of  3,937.    Elapsed: 0:14:38.\n",
      "Batch 1,930  of  3,937.    Elapsed: 0:14:42.\n",
      "Batch 1,940  of  3,937.    Elapsed: 0:14:47.\n",
      "Batch 1,950  of  3,937.    Elapsed: 0:14:51.\n",
      "Batch 1,960  of  3,937.    Elapsed: 0:14:56.\n",
      "Batch 1,970  of  3,937.    Elapsed: 0:15:00.\n",
      "Batch 1,980  of  3,937.    Elapsed: 0:15:05.\n",
      "Batch 1,990  of  3,937.    Elapsed: 0:15:10.\n",
      "Batch 2,000  of  3,937.    Elapsed: 0:15:14.\n",
      "Batch 2,010  of  3,937.    Elapsed: 0:15:19.\n",
      "Batch 2,020  of  3,937.    Elapsed: 0:15:23.\n",
      "Batch 2,030  of  3,937.    Elapsed: 0:15:28.\n",
      "Batch 2,040  of  3,937.    Elapsed: 0:15:32.\n",
      "Batch 2,050  of  3,937.    Elapsed: 0:15:37.\n",
      "Batch 2,060  of  3,937.    Elapsed: 0:15:42.\n",
      "Batch 2,070  of  3,937.    Elapsed: 0:15:46.\n",
      "Batch 2,080  of  3,937.    Elapsed: 0:15:51.\n",
      "Batch 2,090  of  3,937.    Elapsed: 0:15:55.\n",
      "Batch 2,100  of  3,937.    Elapsed: 0:16:00.\n",
      "Batch 2,110  of  3,937.    Elapsed: 0:16:04.\n",
      "Batch 2,120  of  3,937.    Elapsed: 0:16:09.\n",
      "Batch 2,130  of  3,937.    Elapsed: 0:16:14.\n",
      "Batch 2,140  of  3,937.    Elapsed: 0:16:18.\n",
      "Batch 2,150  of  3,937.    Elapsed: 0:16:23.\n",
      "Batch 2,160  of  3,937.    Elapsed: 0:16:27.\n",
      "Batch 2,170  of  3,937.    Elapsed: 0:16:32.\n",
      "Batch 2,180  of  3,937.    Elapsed: 0:16:36.\n",
      "Batch 2,190  of  3,937.    Elapsed: 0:16:41.\n",
      "Batch 2,200  of  3,937.    Elapsed: 0:16:46.\n",
      "Batch 2,210  of  3,937.    Elapsed: 0:16:50.\n",
      "Batch 2,220  of  3,937.    Elapsed: 0:16:55.\n",
      "Batch 2,230  of  3,937.    Elapsed: 0:16:59.\n",
      "Batch 2,240  of  3,937.    Elapsed: 0:17:04.\n",
      "Batch 2,250  of  3,937.    Elapsed: 0:17:08.\n",
      "Batch 2,260  of  3,937.    Elapsed: 0:17:13.\n",
      "Batch 2,270  of  3,937.    Elapsed: 0:17:18.\n",
      "Batch 2,280  of  3,937.    Elapsed: 0:17:22.\n",
      "Batch 2,290  of  3,937.    Elapsed: 0:17:27.\n",
      "Batch 2,300  of  3,937.    Elapsed: 0:17:31.\n",
      "Batch 2,310  of  3,937.    Elapsed: 0:17:36.\n",
      "Batch 2,320  of  3,937.    Elapsed: 0:17:40.\n",
      "Batch 2,330  of  3,937.    Elapsed: 0:17:45.\n",
      "Batch 2,340  of  3,937.    Elapsed: 0:17:50.\n",
      "Batch 2,350  of  3,937.    Elapsed: 0:17:54.\n",
      "Batch 2,360  of  3,937.    Elapsed: 0:17:59.\n",
      "Batch 2,370  of  3,937.    Elapsed: 0:18:03.\n",
      "Batch 2,380  of  3,937.    Elapsed: 0:18:08.\n",
      "Batch 2,390  of  3,937.    Elapsed: 0:18:13.\n",
      "Batch 2,400  of  3,937.    Elapsed: 0:18:17.\n",
      "Batch 2,410  of  3,937.    Elapsed: 0:18:22.\n",
      "Batch 2,420  of  3,937.    Elapsed: 0:18:26.\n",
      "Batch 2,430  of  3,937.    Elapsed: 0:18:31.\n",
      "Batch 2,440  of  3,937.    Elapsed: 0:18:35.\n",
      "Batch 2,450  of  3,937.    Elapsed: 0:18:40.\n",
      "Batch 2,460  of  3,937.    Elapsed: 0:18:45.\n",
      "Batch 2,470  of  3,937.    Elapsed: 0:18:49.\n",
      "Batch 2,480  of  3,937.    Elapsed: 0:18:54.\n",
      "Batch 2,490  of  3,937.    Elapsed: 0:18:58.\n",
      "Batch 2,500  of  3,937.    Elapsed: 0:19:03.\n",
      "Batch 2,510  of  3,937.    Elapsed: 0:19:08.\n",
      "Batch 2,520  of  3,937.    Elapsed: 0:19:12.\n",
      "Batch 2,530  of  3,937.    Elapsed: 0:19:17.\n",
      "Batch 2,540  of  3,937.    Elapsed: 0:19:21.\n",
      "Batch 2,550  of  3,937.    Elapsed: 0:19:26.\n",
      "Batch 2,560  of  3,937.    Elapsed: 0:19:30.\n",
      "Batch 2,570  of  3,937.    Elapsed: 0:19:35.\n",
      "Batch 2,580  of  3,937.    Elapsed: 0:19:40.\n",
      "Batch 2,590  of  3,937.    Elapsed: 0:19:44.\n",
      "Batch 2,600  of  3,937.    Elapsed: 0:19:49.\n",
      "Batch 2,610  of  3,937.    Elapsed: 0:19:53.\n",
      "Batch 2,620  of  3,937.    Elapsed: 0:19:58.\n",
      "Batch 2,630  of  3,937.    Elapsed: 0:20:02.\n",
      "Batch 2,640  of  3,937.    Elapsed: 0:20:07.\n",
      "Batch 2,650  of  3,937.    Elapsed: 0:20:12.\n",
      "Batch 2,660  of  3,937.    Elapsed: 0:20:16.\n",
      "Batch 2,670  of  3,937.    Elapsed: 0:20:21.\n",
      "Batch 2,680  of  3,937.    Elapsed: 0:20:25.\n",
      "Batch 2,690  of  3,937.    Elapsed: 0:20:30.\n",
      "Batch 2,700  of  3,937.    Elapsed: 0:20:34.\n",
      "Batch 2,710  of  3,937.    Elapsed: 0:20:39.\n",
      "Batch 2,720  of  3,937.    Elapsed: 0:20:44.\n",
      "Batch 2,730  of  3,937.    Elapsed: 0:20:48.\n",
      "Batch 2,740  of  3,937.    Elapsed: 0:20:53.\n",
      "Batch 2,750  of  3,937.    Elapsed: 0:20:57.\n",
      "Batch 2,760  of  3,937.    Elapsed: 0:21:02.\n",
      "Batch 2,770  of  3,937.    Elapsed: 0:21:07.\n",
      "Batch 2,780  of  3,937.    Elapsed: 0:21:11.\n",
      "Batch 2,790  of  3,937.    Elapsed: 0:21:16.\n",
      "Batch 2,800  of  3,937.    Elapsed: 0:21:20.\n",
      "Batch 2,810  of  3,937.    Elapsed: 0:21:25.\n",
      "Batch 2,820  of  3,937.    Elapsed: 0:21:29.\n",
      "Batch 2,830  of  3,937.    Elapsed: 0:21:34.\n",
      "Batch 2,840  of  3,937.    Elapsed: 0:21:39.\n",
      "Batch 2,850  of  3,937.    Elapsed: 0:21:43.\n",
      "Batch 2,860  of  3,937.    Elapsed: 0:21:48.\n",
      "Batch 2,870  of  3,937.    Elapsed: 0:21:52.\n",
      "Batch 2,880  of  3,937.    Elapsed: 0:21:57.\n",
      "Batch 2,890  of  3,937.    Elapsed: 0:22:02.\n",
      "Batch 2,900  of  3,937.    Elapsed: 0:22:06.\n",
      "Batch 2,910  of  3,937.    Elapsed: 0:22:11.\n",
      "Batch 2,920  of  3,937.    Elapsed: 0:22:15.\n",
      "Batch 2,930  of  3,937.    Elapsed: 0:22:20.\n",
      "Batch 2,940  of  3,937.    Elapsed: 0:22:25.\n",
      "Batch 2,950  of  3,937.    Elapsed: 0:22:29.\n",
      "Batch 2,960  of  3,937.    Elapsed: 0:22:34.\n",
      "Batch 2,970  of  3,937.    Elapsed: 0:22:38.\n",
      "Batch 2,980  of  3,937.    Elapsed: 0:22:43.\n",
      "Batch 2,990  of  3,937.    Elapsed: 0:22:47.\n",
      "Batch 3,000  of  3,937.    Elapsed: 0:22:52.\n",
      "Batch 3,010  of  3,937.    Elapsed: 0:22:57.\n",
      "Batch 3,020  of  3,937.    Elapsed: 0:23:01.\n",
      "Batch 3,030  of  3,937.    Elapsed: 0:23:06.\n",
      "Batch 3,040  of  3,937.    Elapsed: 0:23:10.\n",
      "Batch 3,050  of  3,937.    Elapsed: 0:23:15.\n",
      "Batch 3,060  of  3,937.    Elapsed: 0:23:19.\n",
      "Batch 3,070  of  3,937.    Elapsed: 0:23:24.\n",
      "Batch 3,080  of  3,937.    Elapsed: 0:23:29.\n",
      "Batch 3,090  of  3,937.    Elapsed: 0:23:33.\n",
      "Batch 3,100  of  3,937.    Elapsed: 0:23:38.\n",
      "Batch 3,110  of  3,937.    Elapsed: 0:23:42.\n",
      "Batch 3,120  of  3,937.    Elapsed: 0:23:47.\n",
      "Batch 3,130  of  3,937.    Elapsed: 0:23:52.\n",
      "Batch 3,140  of  3,937.    Elapsed: 0:23:56.\n",
      "Batch 3,150  of  3,937.    Elapsed: 0:24:01.\n",
      "Batch 3,160  of  3,937.    Elapsed: 0:24:05.\n",
      "Batch 3,170  of  3,937.    Elapsed: 0:24:10.\n",
      "Batch 3,180  of  3,937.    Elapsed: 0:24:15.\n",
      "Batch 3,190  of  3,937.    Elapsed: 0:24:19.\n",
      "Batch 3,200  of  3,937.    Elapsed: 0:24:24.\n",
      "Batch 3,210  of  3,937.    Elapsed: 0:24:28.\n",
      "Batch 3,220  of  3,937.    Elapsed: 0:24:33.\n",
      "Batch 3,230  of  3,937.    Elapsed: 0:24:37.\n",
      "Batch 3,240  of  3,937.    Elapsed: 0:24:42.\n",
      "Batch 3,250  of  3,937.    Elapsed: 0:24:47.\n",
      "Batch 3,260  of  3,937.    Elapsed: 0:24:51.\n",
      "Batch 3,270  of  3,937.    Elapsed: 0:24:56.\n",
      "Batch 3,280  of  3,937.    Elapsed: 0:25:00.\n",
      "Batch 3,290  of  3,937.    Elapsed: 0:25:05.\n",
      "Batch 3,300  of  3,937.    Elapsed: 0:25:09.\n",
      "Batch 3,310  of  3,937.    Elapsed: 0:25:14.\n",
      "Batch 3,320  of  3,937.    Elapsed: 0:25:19.\n",
      "Batch 3,330  of  3,937.    Elapsed: 0:25:23.\n",
      "Batch 3,340  of  3,937.    Elapsed: 0:25:28.\n",
      "Batch 3,350  of  3,937.    Elapsed: 0:25:32.\n",
      "Batch 3,360  of  3,937.    Elapsed: 0:25:37.\n",
      "Batch 3,370  of  3,937.    Elapsed: 0:25:41.\n",
      "Batch 3,380  of  3,937.    Elapsed: 0:25:46.\n",
      "Batch 3,390  of  3,937.    Elapsed: 0:25:51.\n",
      "Batch 3,400  of  3,937.    Elapsed: 0:25:55.\n",
      "Batch 3,410  of  3,937.    Elapsed: 0:26:00.\n",
      "Batch 3,420  of  3,937.    Elapsed: 0:26:04.\n",
      "Batch 3,430  of  3,937.    Elapsed: 0:26:09.\n",
      "Batch 3,440  of  3,937.    Elapsed: 0:26:13.\n",
      "Batch 3,450  of  3,937.    Elapsed: 0:26:18.\n",
      "Batch 3,460  of  3,937.    Elapsed: 0:26:23.\n",
      "Batch 3,470  of  3,937.    Elapsed: 0:26:27.\n",
      "Batch 3,480  of  3,937.    Elapsed: 0:26:32.\n",
      "Batch 3,490  of  3,937.    Elapsed: 0:26:36.\n",
      "Batch 3,500  of  3,937.    Elapsed: 0:26:41.\n",
      "Batch 3,510  of  3,937.    Elapsed: 0:26:45.\n",
      "Batch 3,520  of  3,937.    Elapsed: 0:26:50.\n",
      "Batch 3,530  of  3,937.    Elapsed: 0:26:55.\n",
      "Batch 3,540  of  3,937.    Elapsed: 0:26:59.\n",
      "Batch 3,550  of  3,937.    Elapsed: 0:27:04.\n",
      "Batch 3,560  of  3,937.    Elapsed: 0:27:08.\n",
      "Batch 3,570  of  3,937.    Elapsed: 0:27:13.\n",
      "Batch 3,580  of  3,937.    Elapsed: 0:27:18.\n",
      "Batch 3,590  of  3,937.    Elapsed: 0:27:22.\n",
      "Batch 3,600  of  3,937.    Elapsed: 0:27:27.\n",
      "Batch 3,610  of  3,937.    Elapsed: 0:27:31.\n",
      "Batch 3,620  of  3,937.    Elapsed: 0:27:36.\n",
      "Batch 3,630  of  3,937.    Elapsed: 0:27:40.\n",
      "Batch 3,640  of  3,937.    Elapsed: 0:27:45.\n",
      "Batch 3,650  of  3,937.    Elapsed: 0:27:50.\n",
      "Batch 3,660  of  3,937.    Elapsed: 0:27:54.\n",
      "Batch 3,670  of  3,937.    Elapsed: 0:27:59.\n",
      "Batch 3,680  of  3,937.    Elapsed: 0:28:03.\n",
      "Batch 3,690  of  3,937.    Elapsed: 0:28:08.\n",
      "Batch 3,700  of  3,937.    Elapsed: 0:28:12.\n",
      "Batch 3,710  of  3,937.    Elapsed: 0:28:17.\n",
      "Batch 3,720  of  3,937.    Elapsed: 0:28:22.\n",
      "Batch 3,730  of  3,937.    Elapsed: 0:28:26.\n",
      "Batch 3,740  of  3,937.    Elapsed: 0:28:31.\n",
      "Batch 3,750  of  3,937.    Elapsed: 0:28:35.\n",
      "Batch 3,760  of  3,937.    Elapsed: 0:28:40.\n",
      "Batch 3,770  of  3,937.    Elapsed: 0:28:45.\n",
      "Batch 3,780  of  3,937.    Elapsed: 0:28:49.\n",
      "Batch 3,790  of  3,937.    Elapsed: 0:28:54.\n",
      "Batch 3,800  of  3,937.    Elapsed: 0:28:58.\n",
      "Batch 3,810  of  3,937.    Elapsed: 0:29:03.\n",
      "Batch 3,820  of  3,937.    Elapsed: 0:29:07.\n",
      "Batch 3,830  of  3,937.    Elapsed: 0:29:12.\n",
      "Batch 3,840  of  3,937.    Elapsed: 0:29:17.\n",
      "Batch 3,850  of  3,937.    Elapsed: 0:29:21.\n",
      "Batch 3,860  of  3,937.    Elapsed: 0:29:26.\n",
      "Batch 3,870  of  3,937.    Elapsed: 0:29:30.\n",
      "Batch 3,880  of  3,937.    Elapsed: 0:29:35.\n",
      "Batch 3,890  of  3,937.    Elapsed: 0:29:40.\n",
      "Batch 3,900  of  3,937.    Elapsed: 0:29:44.\n",
      "Batch 3,910  of  3,937.    Elapsed: 0:29:49.\n",
      "Batch 3,920  of  3,937.    Elapsed: 0:29:53.\n",
      "Batch 3,930  of  3,937.    Elapsed: 0:29:58.\n",
      "Average training loss: 0.00\n",
      "Training epoch took: 0:30:01\n",
      "Training completed in 2:00:17 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "seed_val = 1903\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Training Time': training_time,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7241305,
     "status": "ok",
     "timestamp": 1596412661004,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "gXaY-Zul-ZdI",
    "outputId": "3e66a175-cce0-41e3-e993-9a934121b77a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "plt.plot(df_stats['Training Loss'], label=\"Training\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7252662,
     "status": "ok",
     "timestamp": 1596412672366,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "_poTN8q6-ZgT"
   },
   "outputs": [],
   "source": [
    "test_texts = test.text.values\n",
    "test_labels = test.encoded_categories.values\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in test_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,          \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt',  \n",
    "                        truncation=True, \n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(test_labels)\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7363383,
     "status": "ok",
     "timestamp": 1596412783098,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "_kF5iizX-Zjm",
    "outputId": "b978092a-2d68-442d-a81f-d6f9f97fc19a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction started on test data\n",
      "Prediction completed\n"
     ]
    }
   ],
   "source": [
    "print('Prediction started on test data')\n",
    "model.eval()\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  with torch.no_grad():\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('Prediction completed')\n",
    "\n",
    "prediction_set = []\n",
    "\n",
    "for i in range(len(true_labels)):\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  prediction_set.append(pred_labels_i)\n",
    "\n",
    "prediction_scores = [item for sublist in prediction_set for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7363374,
     "status": "ok",
     "timestamp": 1596412783103,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "W6Oe0atz-Zm8",
    "outputId": "82833753-12d4-4af1-e229-8b0f88837d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score:  0.7902427131066003\n",
      "Recall:  0.8072661697125949\n",
      "Precision:  0.8093144574383921\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.928156     0.690473  0.790267      0.809314      0.825778\n",
      "recall         0.684563     0.929969  0.790267      0.807266      0.790267\n",
      "f1-score       0.787963     0.792522  0.790267      0.790243      0.789927\n",
      "support    12833.000000  9710.000000  0.790267  22543.000000  22543.000000\n"
     ]
    }
   ],
   "source": [
    "f_score = f1_score(test_labels, prediction_scores, average='macro')\n",
    "precision = precision_score(test_labels, prediction_scores, average='macro')\n",
    "recall = recall_score(test_labels, prediction_scores, average='macro')\n",
    "\n",
    "print(\"F-Score: \", f_score)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))\n",
    "report = report.rename(columns={'0':'0',\n",
    "                          '1':'1',\n",
    "                          '2':'2',\n",
    "                          '3':'3',\n",
    "                          '4':'4'})\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7363370,
     "status": "ok",
     "timestamp": 1596412783104,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "1px9psg5ZMzh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7363367,
     "status": "ok",
     "timestamp": 1596412783104,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "1C5cmt1MZM3P"
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(test_labels, prediction_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7363365,
     "status": "ok",
     "timestamp": 1596412783105,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "CyEBRvW8ZM6t",
    "outputId": "61705826-94ff-40ed-84d6-41704c1df8c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc6dd71748>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=confusion_matrix(test_labels, prediction_scores)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7364236,
     "status": "ok",
     "timestamp": 1596412783980,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "uYleAuli-Zp0"
   },
   "outputs": [],
   "source": [
    "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7364224,
     "status": "ok",
     "timestamp": 1596412783981,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "x4gDDUkeW7w_",
    "outputId": "1cc83050-abce-4d0d-de49-89e0239e7b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.928156     0.690473  0.790267      0.809314      0.825778\n",
      "recall         0.684563     0.929969  0.790267      0.807266      0.790267\n",
      "f1-score       0.787963     0.792522  0.790267      0.790243      0.789927\n",
      "support    12833.000000  9710.000000  0.790267  22543.000000  22543.000000\n"
     ]
    }
   ],
   "source": [
    "print(report.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7364212,
     "status": "ok",
     "timestamp": 1596412783983,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "sUo4Hqgxaq9c",
    "outputId": "461c0119-2b22-403a-d492-642c9510da72"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[[8785 4048]\\n [ 680 9030]]'"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7364200,
     "status": "ok",
     "timestamp": 1596412783984,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "8goJSAzkqMGE",
    "outputId": "017da742-44c5-4cb4-8c7e-13be7282fc70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8785, 4048],\n",
       "       [ 680, 9030]])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7364187,
     "status": "ok",
     "timestamp": 1596412783985,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "2ftxFCw1whhm",
    "outputId": "1496eb6c-69fa-49b7-b900-ae90b6cbadd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "DoS       7458\n",
      "Probe     2421\n",
      "R2L       2754\n",
      "U2R        200\n",
      "normal    9710\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#training_labels = training.encoded_categories.values\n",
    "print(test.groupby(\"category\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2036,
     "status": "ok",
     "timestamp": 1596412808845,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "auVcgpqYnOUQ",
    "outputId": "2808f99f-33be-4014-b105-57d278b27230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/vocab.txt',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5924,
     "status": "ok",
     "timestamp": 1596412818377,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "o2CY3IE_ncdv",
    "outputId": "addb0bb6-c5c7-48b5-f3d8-3f2feb91f97a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 427992K\n",
      "-rw-r--r-- 1 root root      1K Aug  3 00:00 config.json\n",
      "-rw-r--r-- 1 root root 427752K Aug  3 00:00 pytorch_model.bin\n",
      "-rw-r--r-- 1 root root      1K Aug  3 00:00 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root      1K Aug  3 00:00 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root    227K Aug  3 00:00 vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -l --block-size=K ./model_save/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5064,
     "status": "ok",
     "timestamp": 1596412901979,
     "user": {
      "displayName": "Kahraman koştaş",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz1P7fzID2R4O_AUPpUS69mK--gaX6FsLYnJLsIA=s64",
      "userId": "10886631466279441235"
     },
     "user_tz": -60
    },
    "id": "87hzFj_2nnw3"
   },
   "outputs": [],
   "source": [
    "!cp -r ./model_save/ \"/content/drive/My Drive/resource/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rp_Vd-QDoJoL"
   },
   "outputs": [],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deneme__binary",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0318e852cb824e878ae18e804de01dea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "035fba578fa64556af099baea4e26b89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08ac5211d1d1457d887c05637b765cba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "15b7f2dc8b2d4672872fabc4ca1fd406": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17f3da9b03854f55a8505d1a997c6c18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fb81158de864bf6824f480a5b4a9d88",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_385fcdef15b544209f67c26ec3d8370c",
      "value": 433
     }
    },
    "1bb55a0c4c4a4448a39bb66fb0e43851": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_035fba578fa64556af099baea4e26b89",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08ac5211d1d1457d887c05637b765cba",
      "value": 231508
     }
    },
    "1e733c554f4c4ca490794fb866672710": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17f3da9b03854f55a8505d1a997c6c18",
       "IPY_MODEL_22763bcb42b64b9d9f6988e145370ff4"
      ],
      "layout": "IPY_MODEL_5411e6b4691c43a396a4e9a88e54e114"
     }
    },
    "1fb81158de864bf6824f480a5b4a9d88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21a9dd1473424c2ca62e53980ee10439": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22763bcb42b64b9d9f6988e145370ff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15b7f2dc8b2d4672872fabc4ca1fd406",
      "placeholder": "​",
      "style": "IPY_MODEL_0318e852cb824e878ae18e804de01dea",
      "value": " 433/433 [00:06&lt;00:00, 62.7B/s]"
     }
    },
    "2e50e4763fee4f0a8a961179312985b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff8fdb69821c4780ac10d26965e350fe",
      "placeholder": "​",
      "style": "IPY_MODEL_d06ec224e4844886948b90d154185ddb",
      "value": " 440M/440M [00:06&lt;00:00, 71.6MB/s]"
     }
    },
    "385fcdef15b544209f67c26ec3d8370c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "44651e87ca8b4ab4a1880859ec7cea7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1bb55a0c4c4a4448a39bb66fb0e43851",
       "IPY_MODEL_ea93e197c46c4ed8981fea8d9e19c519"
      ],
      "layout": "IPY_MODEL_21a9dd1473424c2ca62e53980ee10439"
     }
    },
    "45c40ff09909429a9ebfacb711811549": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8272b67f36384027804f020609eba4dd",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0e1e026305a4dc5aed6f1640957d7ac",
      "value": 440473133
     }
    },
    "5411e6b4691c43a396a4e9a88e54e114": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ad074cbcbff4e038804091fb1fd6eaa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8272b67f36384027804f020609eba4dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a4909a5b6e84526af54a013a2ce0d0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b80020ed3de9443ebef2a6dcbc7927d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45c40ff09909429a9ebfacb711811549",
       "IPY_MODEL_2e50e4763fee4f0a8a961179312985b9"
      ],
      "layout": "IPY_MODEL_7ad074cbcbff4e038804091fb1fd6eaa"
     }
    },
    "d06ec224e4844886948b90d154185ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0e1e026305a4dc5aed6f1640957d7ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ea93e197c46c4ed8981fea8d9e19c519": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f351d360263a4bb3bd2e47db1a549338",
      "placeholder": "​",
      "style": "IPY_MODEL_8a4909a5b6e84526af54a013a2ce0d0d",
      "value": " 232k/232k [00:00&lt;00:00, 255kB/s]"
     }
    },
    "f351d360263a4bb3bd2e47db1a549338": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff8fdb69821c4780ac10d26965e350fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
